Abstract
Homomorphic network coding signature is one of the countermeasures designed
to combat the pollution attack when applying the vanilla network coding. The
project is to compare the computational overhead of homomorphic signatures in
random oracle/standard models on the intermediate nodes. The purpose is driven
by the fact that a provable scheme in random oracle is not going to be a hundred
percent secure when put into practice because of the di?culty of the instantia-
tion of random oracle. If homomorphic signature in standard model has the same
performance as the scheme in random oracle, the standard scheme would be pre-
ferred. To this end, we select four secure homomorphic network coding signature
schemes and divide them into two groups, two RSA-based schemes[6][8] and two
bilinear-based schemes[8][9]. The schemes in each group have the same algebraic
setting and the comparisons are carried out in each group separately.
To conclude, what has been done in our project is shown as follows:
• A theoretical comparison of the schemes in the same group is discussed in
Section 4.5.
• The communication model of homomorphic signature shows the three oper-
ations(vry NC(), vry Sig() and combine()) that will result in the computa-
tional overhead on the intermediate nodes, see Section 5.2.
• The identical implementation of the operation vry NC() of the schemes in
thesamegroupwillnotleadtothetimedi?erence; therefore,thecomparison
will concentrate on vry Sig() and combine(), see Section 6.1.
• The time di?erence of two RSA-based schemes is caused by the combine()
operation since vry Sig()costs approximately the same time in two schemes,
see Section 7.1.4. The reason why the time di?erence of two combine() is
the multi-exponentiation, see the Analysis part in Section 7.1.2.
• The time di?erence of two bilinear-based schemes is caused by the vry Sig()
operationsincecombine()costsapproximatelythesametimeintwoschemes,
see Section 7.2.3. The reason why the time di?erence of two vry Sig() is the
exponentiation in bilinear groups, see the Analysis part in Section 7.2.1.
• Homomorphic signatures in random oracle/standard models are not compa-
rableespecially when thenetwork coding applicationisforsending largeﬁles
and requires a higher security level; whereas, they are somewhat comparable
when the size of ﬁle is moderate and requires moderate security level, see
Section 8.1.Acknowledgements
I would like to express my deepest thanks to my supervisor, Bogdan Warinschi,
for his continuous support to the project, his invaluable comments and his encour-
agement for the past six months.
I would also like to thank Elizabeth Quaglia fromthe University of London forher
patience and her detailed explanations of my questions concerning the project.
Thanks to my family and friends for their support and encouragement.Contents
1 Introduction 1
2 Background 3
2.1 Linear Network Coding . . . . . . . . . . . . . . . . . . . . . . . . . 3
2.2 Dealing with Pollution Attack . . . . . . . . . . . . . . . . . . . . . 3
2.3 Our Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . 6
3 Deﬁnitions and Preliminaries 8
3.1 Bilinear Groups . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8
3.2 Computational Assumptions . . . . . . . . . . . . . . . . . . . . . . 8
3.3 Random and Standard Oracle Model . . . . . . . . . . . . . . . . . 10
3.4 (Homomorphic) Network Coding Signature . . . . . . . . . . . . . . 10
4 Homomorphic Network Coding Signatures 13
4.1 RSA-Based Scheme in Random Oracle RRSA . . . . . . . . . . . . 13
4.2 RSA-Based Scheme in Standard Model SRSA . . . . . . . . . . . . 15
4.3 Scheme over Bilinear Group in Random Oracle RCDH . . . . . . . 17
4.4 Scheme over Bilinear Group in Standard Model SSDH . . . . . . . 18
4.5 Summary and Comparison . . . . . . . . . . . . . . . . . . . . . . . 19
5 Communication Models 21
5.1 Network Coding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
5.2 Homomorphic Signature . . . . . . . . . . . . . . . . . . . . . . . . 21
5.3 Summary and Comparison . . . . . . . . . . . . . . . . . . . . . . . 22
6 Implementations 24
6.1 Gaussian Elimination . . . . . . . . . . . . . . . . . . . . . . . . . . 24
6.2 Implementations of RRSA and SRSA . . . . . . . . . . . . . . . . . 26
6.2.1 Implementation Comparisons . . . . . . . . . . . . . . . . . 26
6.2.2 Parameter Generations . . . . . . . . . . . . . . . . . . . . . 27
6.3 Implementations of RCDH and SSDH . . . . . . . . . . . . . . . . 28
6.3.1 Implementation Comparisons . . . . . . . . . . . . . . . . . 28
6.3.2 Parameter Generations and Library Functions . . . . . . . . 29
7 Results and Analyses 32
7.1 Comparisons of RRSA and SRSA . . . . . . . . . . . . . . . . . . . 32
7.1.1 Veriﬁcation Algorithm . . . . . . . . . . . . . . . . . . . . . 32
7.1.2 Combining Algorithm. . . . . . . . . . . . . . . . . . . . . . 34
7.1.3 Security Parameter k . . . . . . . . . . . . . . . . . . . . . . 36
7.1.4 Summary and Comparison . . . . . . . . . . . . . . . . . . 387.2 Comparisons of RCDH and SSDH . . . . . . . . . . . . . . . . . . 40
7.2.1 Veriﬁcation Algorithm . . . . . . . . . . . . . . . . . . . . . 40
7.2.2 Combining Algorithm. . . . . . . . . . . . . . . . . . . . . . 43
7.2.3 Summary and Comparison . . . . . . . . . . . . . . . . . . 45
7.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46
8 Conclusions and Evaluations 47
8.1 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47
8.2 Critical Evaluations . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
8.3 Possible Extensions . . . . . . . . . . . . . . . . . . . . . . . . . . . 511 Introduction
Network coding [1][25] is a novel and elegant routing technique that serves as an
alternativetothetraditionalnetworkroutingscheme. Di?erentfromthestoreand
forward mechanism, network coding allows the intermediate nodes to combine the
received packets before transmitting. The advantages brought by network coding
have made it suitable for wireless and ad-hoc network topologies where a central
control is hard. The most noticeable beneﬁt is the signiﬁcant improvement of net-
work performance, that is, the increase in the information ﬂow in the distributed
networks. In addition, network coding o?ers an approach to improve the network
robustness resulting from packet loss since the target nodecan recover the original
ﬁle if it receives a su?cient number of correct packets. According to the way the
intermediate nodes modify the received packets, network coding is divided into
linear and non-linear network coding; our work will focus on linear network cod-
ing. Linear network coding is saying that the intermediate nodes make a linear
combination on the incoming packets.
While network coding maximally improves the throughput in the network ﬂow,
it is susceptible to pollution attacks where the intermediate nodes may behave
maliciously and modify the packets in a wrong way before transmitting. The in-
termediate nodes will combine the corrupted packets into new invalid packets and
then propagate them into the network, which will lead to the phenomenon, pollu-
tion propagation. There are two main classes of techniques to deal with pollution
attack, information-theoretic approaches and cryptographic approaches. The ﬁrst
one introduces redundancy to the packets which signiﬁcantly increases the over-
head in communication. The other one is based on one of the two primitives:
homomorphic hash functions and homomorphic signatures. We will give a more
detailed description of these two techniques in Section 2.2.
In the work, we will concentrate on homomorphic network coding signatures.
According to the oracle the schemes use, there are two kinds of homomorphic
signatures: the schemes in random oracle model and the schemes in standard
model. As the names imply, the random signatures are deﬁned over random ora-
cle, while the standard signatures work over non-random oracle. The works [5][10]
show that to implement a provable secure cryptographic scheme, an appropriate
random oracle(always the hash function) is needed; however, it is di?cult to ﬁnd
a hash function that generates true random outputs and this has resulted in a
secure scheme in random oracle turning out to be insecure when implementing.
Consequently, a provable standard scheme which performs at least as well as the
random scheme would be preferred to tackle the problem introduced by the in-
stantiation of random oracle. This has put forward to the research of our project,
1that is, to compare the performance of homomorphic signatures in random oracle
and homomorphic signatures in standard model in terms of the processing delay
on the intermediate nodes in the network from a practical point of view.
Speciﬁcally, the work will investigate the processing overhead of four secure ho-
momorphic signature schemes in random oracle/standard models according to the
cryptographic overhead during transmission. These comparisons are based on the
operationsontheintermediatenodesthatwillleadtothecomputationaloverhead.
Four secure homomorphic network coding signatures are illustrated as follows:
• RSA-based signature scheme in random oracle model proposed by Gennaro
et al. in [13];
• RSA-based signature scheme in standard model presented by Catalano et al.
in [11];
• Signature scheme over bilinear groups based on the co-computational Di?e
Hellman (co-CDH) assumption in random oracle in [7] by Boneh et al.;
• Signature scheme over bilinear groups under q-Strong Di?e-Hellman (q-
SDH) assumption in standard model in [11] by Gennaro et al..
Noticethattheﬁrsttwoschemesandthelasttwobothhavesimilaralgebraicback-
grounds and they have been proven to be secure under respective computational
assumptions. Therefore, we separate four schemes into two groups, the ﬁrst two
RSA-based schemes in one group(refer to RSAGroup) and the last two schemes
work over bilinear groups(refer to BilinearGroup). Comparisons in each groupwill
be discussed respectively.
Outline of our work. We do not assume any background in network coding
and so give a brief introduction of related information of network coding and
mathematical basis. In Chapter 2, we give the background of linear network cod-
ing and the related techniques on combating pollution attack which is followed
by our contributions. Relevant computational assumptions and deﬁnitions are il-
lustrated in Chapter 3. Chapter 4 discusses four signature schemes in detail and
gives a comparison from a theoretical standpoint at the end. Chapter 5 is the
communication models of network coding and homomorphic signature; we will il-
lustrate their operation di?erences and then conclude what operations will lead to
cryptographic overhead. The implementation details of four schemes are given in
Chapter 6 and Chapter 7 gives an illustration of implementation results which are
associated with theoretical analyses. Chapter 8 concludes what we have done and
gives a critical evaluation of ourwork which is followed by fourpossible extensions
of the project.
22 Background
2.1 Linear Network Coding
In linear network coding [25], a ﬁleV is regarded as a set of n-dimensional vec-
(1) (m)
tors (v ,...,v ) deﬁned over some ﬁnite ﬁelds or the integers. On the source
node, when a ﬁleV is to be transmitted, m(m? n) properly augmented vectors
(1) (m) (i) (i) (i)
w ,...,w are created where w is the v prepended by a unit vector u of
length m with 1 in thei-th position and 0 in the others. Then the augmented vec-
(i) (i) (i)
tors w can be expressed as (u ,v ). In this way, the set of augmented vectors
(1) (m) m+n
(w ,...,w ) forms a basis of a subspaceW inF .
(1) (?)
Thei-thintermediate node receives ? vectorsw ,...,w fromits incoming edges
P
?
(j)
and combines them into a new vector w = ? w , where ? is chosen from
i,j i,j
j=1
the underlying ﬁeld. After that, the node sends out the resulting vector through
its outgoing edges. The coe?cient ? used by the i-th intermediate node can
i,j
be chosen at random by each node, constructed by a central authority or set by
the network applications; we will consider the ﬁrst case which is called random
network coding. As illustrated in [25][14][16], random network coding has almost
the same performance as network coding with ﬁxed coe?cients.
In order to recover the original ﬁle, any destination node must receive at least
(1) (m)
m correct vectors, say (w ,...,w ). Each received vector has the formdescribed
(i) (i) (i) (i) (i)
above, that is w = (u ,v ), such that u is the left-most m positions and v
(1) (m)
is the right-most n positions. LetV be the matrix of m vectors (v ,...,v ) and
(1) (m)
U be (u ,...,u ). The original ﬁle can then be obtained from
?1
V =U ·V.
In fact, the linear network coding scheme can be applied to the original ﬁle set
(1) (m (1) (m)
(v ,...,v ) but not necessarily to the properly augmented vectors w ,...,w ;
however, in our work, we assume that the scheme is running on a properly aug-
mented basis.
2.2 Dealing with Pollution Attack
Linear network coding described above serves as a technique to successfully re-
cover the original ﬁle and improves the network robustness in the network since
target nodes can recover the original ﬁle from any m uncorrupted and linearly
independent packets. However, the honest behaviour of all involved nodes and a
secure communication channel are required for network coding to work correctly.
As mentioned in Chapter 1, an intermediate node may behave maliciously and
3modify the packets in a bad way before sending them into the network; this will
result in pollution propagation and the impossible reconstruction of the ﬁle.
Before we examine the methods of combating pollution propagation, it is mean-
ingful to discuss two trivial schemes that are proposed to deal with the pollution
attack but fail to solve the problem [13][11]. One is to sign each packet on the
source node before transmitting which is infeasible as the network coding mech-
anism combines packets on the intermediate nodes(this makes the veriﬁcation of
the combined packet become impossible). The other one is to sign the entire ﬁle
on the source node which can help the destination nodes to verify a received ﬁle;
nonetheless, once the invalid packets are injected into the network, the receivers
are under a Denial-of-Service attack because the veriﬁcation process can only be
carried out when the ﬁles are recovered.
We have mentioned the two main approaches to deal with data pollution when
using linear network coding in Chapter 1, information-theoretic approaches and
cryptographic approaches.
Information-theoretic approaches. Information-theoretic schemes introduce
redundancy to the original packets by using error-correcting code for the receivers
to recover the original ﬁle if su?cient valid packets are received [15][16][18]. The
security of these methods does not depend on computational assumptions but
on the additional information in the packets which will signiﬁcantly increase the
communicational overhead. Moreover, to successfully retrieve the originalﬁle, this
scheme allows only a limited number of corrupted nodes, maliciously modiﬁed
packets and insecure communication links.
Cryptographicapproaches. Cryptographicschemesarebasedoncryptographic
assumptions and can achieve lower overhead in communication than information-
theoretic approaches. These methods allow the receiver to verify the incoming
packets before combining them; and, more importantly, they make it possible for
a target node which receives less than m valid packets to recover a portion of
the ﬁle. In this way, the cryptographic approach o?ers an e?cient mechanism to
control malicious nodes by allowing the honest node to check the correctness of
incoming packets. The cryptographic approach is based on either homomorphic
hashing [13][17][7] or homomorphic signature[13][7][12].
Our work will concentrate on network coding schemes using homomorphic sig-
natures. A network coding scheme based on homomorphic signatures has the fol-
lowing linear homomorphic property [13][11]: for any vectors a,b and scalars ?,?,
4? ?
the equation Sign(?a +?b) = Sign(a) Sign(b) always holds. In linear network
coding, homomorphic property means that there exists a combining algorithm for
P
?
(i)
an intermediate node to produce a valid signature ? on vector w = ?w
i
i=1
(1) (?)
upon ? signature ? ,...,? corresponding to ? incoming vectors w ,...,w and
1 ?
scalar coe?cients ? ,...,? .
1 ?
Related works. There are a few homomorphic network coding schemes in the
random oracle model. Boneh et al. ﬁrst introduce the deﬁnition of network cod-
ing signature scheme and propose a speciﬁc construction of homomorphic network
coding signature scheme over bilinear groups in [7](details will be discussed in
Section 4.3); this scheme has proved to be secure under the Computational De?e-
Hellman (CDH) assumption. In 2010, another concrete example of homomorphic
network coding built on standard RSA assumption is presented by Gennaro et
al. in [13](details will be discussed in Section 4.1); Catalano et al. show that we
can apply small coe?cients for linear combinations to improve the performance
regardless of whether the scheme works over a large ﬁnite ﬁeld or integers. Boneh
and Freeman propose one homomorphic network coding signature scheme in [9]
based on lattices and its security depends on the problem of searching short vec-
tors in integer lattices; this construction allows the intermediate nodes to verify
vectors over binary ﬁelds. In later work by Boneh and Freeman in [8], another ho-
momorphic network signature scheme for polynomial functions is introduced; it is
the ﬁrst scheme to evaluate multivariate polynomials rather than linear functions;
and it has proved to be secure by using ideal lattices in random oracle.
In 2011, Attrapadung et al. [2] introduce the ﬁrst homomorphic network cod-
ing scheme deﬁned over bilinear groups of composite order in standard model;
the security of this construction is proved by using the dual encryption technique
proposed by Waters [26]. However, the scheme has resulted in expensive compu-
tational overhead because of the dependence on groups of composite orders; and
even though the order of bilinear groups is changed to a prime number, the over-
headisstillexpensive whencomparedtoothersignatureschemes inrandomoracle
model. In the same year, Catalano et al. apply the notion of Adaptive Pseudo-
free groups in homomorphic network coding signature in [12]; its security has been
proved under strong RSA assumption in standard model. In comparison to the
ﬁrst RSA-based scheme in random oracle [13], the computational overhead of this
scheme is not so signiﬁcant; nonetheless, the size of the signature is much larger
because of the larger random exponent. The two most recent signature schemes
in standard model are presented by Catalano et al. in [11] which we are going
to discuss in our project, one is based on RSA assumption and the other one on
q-SDH assumption.
52.3 Our Contributions
In this project, we examine how the oracle models(random oracle and standard)
a?ect the performance of secure homomorphic network coding signature schemes
from the perspective of computational overhead. To this end, the two most recent
signature schemes in standard model are chosen and compared with the other two
inrandomoracledeﬁnedover thesamealgebraicbackgrounds. Fourhomomorphic
signatures are divided into two groups, two RSA-based schemes(RSAGroup) and
two bilinear-based schemes(BilinearGroup); and the comparison is carried out in
each group separately.
In Chapter 5, we will see that three operations(vry NC(), vry Sig() and
combine()) is going to cause the computational overhead in homomorphic
signature; among those operations, the comparison in our work concentrates on
vry Sig() and combine() since the implementations of vry NC() of the schemes in
the same group are identical. combine() causes the time di?erence of two schemes
in RSAGroup because the standard scheme needs to do extra computations(the
multi-exponentiation is the most costly one). vry Sig() is the reason of the
time di?erence of two schemes in BilinearGroup as four extra computations(the
exponentiation in bilinear groups is the most costly one) in bilinear groups are
required in standard scheme. In addition, the time di?erence becomes signiﬁcant
as the number of downloaded blocks, the dimension of the information vectors
and the security level increase.
Four homomorphic signatures are implemented and the experimental re-
sults are illustrated and analysed closely related to the deﬁnitions of the schemes.
Based on the results, we have found three key points. At ﬁrst, schemes in random
oracle/standard models are not comparable especially when (1) the number
of downloaded blocks on the intermediate nodes is large, (2) the dimension
of the initial vectors before prepended with unit vectors is large, and (3) the
applications require a higher security level by increasing the size of the security
parameters which may also result in the increase in the size of other parameters;
the above conditions will signiﬁcantly raise the time di?erence of the schemes
in di?erent oracle models. Besides, schemes in random oracle/standard models
are somewhat comparable when the generation size is small and the security
parameter is moderate. This means that to transmit a small ﬁle or to use a
moderate security parameter, the performance of the standard scheme is in
the same e?ciency class as that of the random oracle schemes. Small ﬁles or
a moderate security parameter will greatly save the computation time on the
intermediate nodes; however, the schemes in standard model still need more time
and the requirement is that the extra time is in a tolerable range. Finally, a more
6customized implementation should be introduced to achieve a better network
performance. To design application-based signature schemes is essential under
the circumstances that e?ciency and security are both important while how fast
and how secure vary in di?erent applications.
The words ’large’, ’small’ and ’moderate’ we use in the above paragraph
are closely related to the network coding applications and can only be discussed
when a certain application environment is set; this is not in the scope of our
project. Amoreprecise analysis ofthe schemes inrandomoracle/standard models
will be illustrated in later chapters.
73 Deﬁnitions and Preliminaries
Inthischapter, weintroducerelevantmathematicalbackgroundsusedinourwork,
bilineargroups,threecomputationalassumptionsandtherandomoracle/standard
models, and the deﬁnitions of (homomorphic) network coding signatures. Let
+
negl(n)denoteanegligiblefunctionmappingfromN toR whereninthischapter
is the security parameter.
3.1 Bilinear Groups
In what follows we give a description of the deﬁnition of bilinear groups as done
in [7].
Deﬁnition 1(Bilinear Groups) A bilinear group can be expressed as a
?
tuple (G,G,G ,e,?) and the tuple has the following properties:
T
?
1. G,G andG arethree cyclic groups of the same prime order, and the group
T
operationsandrandomsamplinginthesegroupscanbecomputede?ciently.
?
2. There exists an e?ciently computable map e : G?G ? G with the
T
following two properties:
a b ab
(a) Bilinearity: the equation e(g ,h ) = e(g,h) holds for any g?G,h?
?
G and a,b?Z.
?
(b) Non-degeneracy: if g and h are generators of groups G andG respec-
tively, then e(g,h) is the generator ofG .
T
?
3. There is an e?ciently computable isomorphism, ? :G ?G.
The cryptographic applications require that the discrete logarithm problem is dif-
? x
ﬁcult in the bilinear groupsG,G andG ; that is, given g, g in the same groups,
T
it is infeasible to ﬁnd x.
3.2 Computational Assumptions
We set out by introducing the RSA assumption, then the co-CDH assumption,
and ﬁnally the q-SDH assumption.
To deﬁne the RSA assumption, we ﬁrst consider anRSA experiment RSA (n)
A,Gen
for a given algorithmA and security parameter n. The parameter generation
n n
phase Gen(1 ) runs on the input 1 to obtain (N,e,d), where N is an RSA
modulus, integer e > 0 is relatively prime to ?(N) and integer d > 0 satisfying
8?
ed? 1 (mod ?(N)). y is chosen randomly fromZ . AlgorithmA is given N,e,y
N
? e
and outputs x? Z . The output of the experiment is 1 if the equation x ? y
N
(mod N) holds, and 0 otherwise.
Next, wecangivethedeﬁnitionofRSAassumptionbasedontheRSAexperiment.
Deﬁnition 2(RSA Assumption) The RSA problem is hard relative to
RSA experiment RSA (n) if for any probabilistic polynomial-time algorithm
A,Gen
A the following inequality holds:
Pr[RSA (n)= 1]≤negl(n).
A,Gen
? ?
Let G and G be two cyclic groups of prime order p, and g and g are the
? ?
generators of G and G respectively. We say (G,G) are bilinear groups if
?
G is isomorphic to G and there exists a group G satisfying a bilinear map
T
?
e :G?G ?G .
T
We describe the co-CDH problem based on the deﬁnition of bilinear groups. The
? x ? ? x
co-CDH problem [7] in (G,G) is deﬁned as to compute g given g,g and (g )
? ?
where G, G, g and g are as deﬁned above. Let co-CDH (n) be a co-CDH
A,Gen
experiment; this experiment outputs 1 when the co-CDH problem is solved and 0
if not.
Deﬁnition 3(co-CDH Assumption) The co-CDH problem is hard relative
to co-CDH experiment co-CDH (n) if for any probabilistic polynomial-time
A,Gen
algorithmA, the following inequality holds:
Pr[co?CDH (n)(n) =1]≤negl(n).
A,Gen
q-Strong Di?e Hellman Assumption(q-SDH) was ﬁrst introduced by Boneh
and Boyen in [6] and its deﬁnition is built on the bilinear groups. q-SDH problem
can be reduced to the CDH problem.
?
Deﬁnition 4(q-SDH Assumption) q-SDH Assumption in (G,G) states
that for any probabilistic polynomial-time algorithmA which is given a (q +2)-
1
2 q
? ? x ? x ? x
x+c
tuple (g,g,(g) ,(g) ,...,(g) ) and outputs a pair (c,g ) satisfying the
following inequality:
1
2 q
? ? x ? x ? x
x+c
Pr[A(g,g,(g) ,(g) ,...,(g) )= (c,g )]≤negl(n)
9?
where x is chosen randomly, c?Z and n is the security parameter.
N
3.3 Random and Standard Oracle Model
Wecategorizethehomomorphicnetworkcodingsignatureschemes intotwo classes
in terms of the oracle it uses, the random oracle signature and the standard model
signature. The schemes in random oracle uses random oracle; while, the schemes
in standard model doesn’t use random oracle.
The paradigm of random oracle model [5][10] is that a scheme is ﬁrst de-
signed and proved to be secure using random oracle H and then implemented
by instantiating the random oracle H with a hash function H(x). Canetti et al.
show in [10] that some existing cryptographic schemes are secure when assuming
the true random oracle exists; however, they turn out to be insecure when being
implemented; that is, in random oracle model, theoretical security does not imply
practical security since there does not exist a cryptographic hash function that
can mimic a true random oracle. On the contrary, in [5], Bellare et al. propose
that, random oracles are practical by showing that an appropriately chosen hash
function(such as standard hash function used in a non-standard way) is able to
retain the provable security of the cryptographic scheme.
The disadvantages random oracle brings have encouraged the research of
the scheme in standard model and, in the ﬁeld of homomorphic network coding,
several signature schemes in standard model have been proposed. However, most
of them have either worse performance when compared to the schemes in random
oracle or expensive communicational overhead. The two most recent standard
signature schemes in [11] are said to be in the same e?ciency class as the random
schemes [13][7] that work over the same algebraic settings; we will examine it
from an experimental perspective later.
3.4 (Homomorphic) Network Coding Signature
Boneh et al. ﬁrst abstract the problem of network coding signature scheme in
m+n
[7]. A network coding scheme is the one that signs a subspaceW?F on the
p
source nodes such that, on the intermediate nodes, vector w?W will be accepted
and w?/W will be rejected. In this section, we are going to show the deﬁnitions
of the (homomorphic) network coding signature scheme and the security notion
of network coding signature according to [7].
On the source node, each ﬁle will be assigned with a unique ﬁle identiﬁer
fid for honest nodes to distinguish multiple ﬁles during transmission. The
10ﬁle identiﬁer fid can be the ﬁle name or chosen randomly from a predeﬁned
samplable set. m is the dimension of vector spaces and n is the upper bound of
the dimension of initial information vectors. We assume the ﬁle identiﬁers are
chosen from setI and the dimension of the initial vector is set to l.
Deﬁnition 5 A Network Coding Signature Scheme is a tuple of three
probabilistic polynomial-time algorithms (Gen, Sign, Vrfy) satisfying the
following:
k
Gen(1 , m, n). The key-generation algorithm Gen takes as input security pa-
rameter k and two integers m,n where m and n are as deﬁned above. It
outputs a pair of keys (vk,sk) where vk is the veriﬁcation key and sk is the
secret key.
Sign(sk, fid,W). The signing algorithm takes as input a secret key sk, a
ﬁle identiﬁer fid ? I and a m-dimensional subspaceW of basis vectors
(1) (m) m+l (i)
w ,...,w ? F , 1 ≤ l ≤ n. It outputs m tuples (fid,w ,? ),
i
1≤i≤m.
Vrfy(vk, fid, w, ?). The veriﬁcation algorithm takes as input a veriﬁcation key
vk, a ﬁle identiﬁer fid?I, a vector w and a signature ?. It outputs 1 if
w?W or 0 if w?/W.
k
It is required that from every k, every (vk,sk) output by Gen(1 ), and all
m+l
W?F , 1≤l≤n, it holds that Vrfy(vk, fid, w, Sign(sk, fid,W)) = 1 where
w?W.
Security of Network Coding Signatures. To show the security notion
of the network coding signature scheme, we describe the game between a
k
challenger and an adversary. At the setup phase, the challenger runs on Gen(1 ,
m, n) to obtain (vk, sk) and gives the public key vk to the adversary. At the
signature queries phase, the adversary is allowed to query signatures on vector
m+l
spacesW? F , 1≤ l≤ n. If the adversary asks for the signature on vector
spaceW, the challenger randomly chooses a ﬁle identiﬁer fid ?I and computes
i
? ?Sign(sk, fid ,W ) and sends ? back to the adversary. Finally, the adversary
i i i i
? ? ?
outputs a forgery (fid ,w ,? ).
The game between the adversary and the challenger is used to deﬁne the
security notion of network coding signature schemes. The adversary wins the
? ? ? ?
game if Vrfy(vk,fid ,w ,? )= 1 and either (1) fid 6= fid , for all i(type-I
i
? ?
forgery), or (2)fid =fid , for some i, but w ?/W (type-II forgery). A signature
i i
scheme is secure if and only if any probabilistic, polynomial-time adversary can
11win the game with at most negligible probability.
Homomorphic network coding signature is a special case of network coding
signature; it is a network coding signature with the homomorphic property. Next,
we give the formal deﬁnition of homomorphic network coding signature as done
by Boneh et al. in [7].
Deﬁnition 6 A Homomorphic Network Coding Signature Scheme
is a tuple of four probabilistic polynomial-time algorithms (Gen, Sign, Vrfy,
Combine) satisfying the following:
k
Gen(1 , m, n). Thekey-generationalgorithmGentakesasinputsecurityparam-
eter k and two integer m,n where m and n are as deﬁned above. It outputs
a pair of keys (vk, sk) where vk is the veriﬁcation key and sk is the secret
key.
Sign(sk, fid,W). The signing algorithm takes as input a secret key sk, a
ﬁle identiﬁer fid ? I and a m-dimensional subspaceW of basis vectors
(1) (m) m+l (i)
w ,...,w ?F , 1≤ l≤ n. It outputs m tuples (fid,w ,? ) where ?
i i
is the signature.
Vrfy(vk, fid, w, ?). The veriﬁcation algorithm takes as input a veriﬁcation key
vk, a ﬁle identiﬁer fid?I, a vector w and a signature ?. It outputs 1 if
w?W or 0 if w?/W.
?
(i)
Combine(vk, fid,{(w ,?,? )} ). We assume the intermediate node receives
i i
1
? incoming packets. The combining algorithm takes as input a veriﬁcation
(i)
key vk, a ﬁle identiﬁer fid?I and a set of triples (w ,?,? ). ? is the
i i i
(i)
signature on the vector w and scalar ? is in F. If all input signatures ?
i i
P
?
(i)
arevalid, then? isavalidsignaturefor ?w . Itoutputsthesignature
i
i=1
?.
k
It is required that from every k, every (vk,sk) output by Gen(1 ), the following
holds:
m+l
1. for all fid?I and all w? F , 1≤ l≤ n, if ??Sign(sk, fid, w), then
Vrfy(vk, fid, w, ?) = 1.
(i) m+l
2. for all fid ? I, any w ? F , 1 ≤ l ≤ n and all sets of triples
?
(i) (i)
{(w ,?,? )} , if Vrfy(vk, fid, w , ? ) =1 for all i, then it holds that
i i i
1
P
?
(i) (i)
Vrfy(vk, fid, ?w , Combine(vk, fid,{(w ,?,? )} )) = 1.
i i i
1
124 Homomorphic Network Coding Signatures
Inthischapter, wewillillustratethedeﬁnitions offourhomomorphicnetwork cod-
ing signature schemes in random oracle/standard models. The two homomorphic
RSA-Based signature schemes will be examined ﬁrst and then the other two over
bilinear groups. Let m be the number of initial vectors and n the upper bound
to the dimension of the information vectors and m,n > 0. M denotes the upper
bound of the coordinates in the initial vectors. Since the values of m and M are
set by the network coding applications or the signature schemes in advance, the
total length of information in each block v is determined if the ﬁle size is known.
i
Therefore, we can play with n to adjust M and m in the deﬁned scope. In this
chapter, we assume thatthe dimension of the informationvectorsl is always equal
to n.
4.1 RSA-Based Scheme in Random OracleRRSA
In this section, we give a precise description of the RSA-based scheme in random
oracle(to which we refer to RRSA, R stands for random oracle).
In RRSA construction, parameter L is used to deﬁne the upper bound of
the distance from the source node to the targets. The beneﬁt of choosing L
is to achieve a good decoding probability when the distance is limited to≤ L;
normally, L is not too large and is ﬁxed to 20 in our implementation. Given
L, a bound B is deﬁned to be the upper bound of components in any vector
L
u in transit and satisﬁes B = (mQ) . Then the largest possible coordinates
? ?
in any vector u is BM to which we refer B , that is, B = BM. Prime Q
deﬁnes the domain Z = {0,...,Q? 1} from which the intermediate nodes
Q
choose coe?cients for linear combination. Speciﬁcally, the intermediate node will
compute a linear combination of valid incoming packets over the integers with the
coe?cients randomly selected from the domain Z . Random oracle is simulated
Q
by using a hash function H and this function takes a ﬁle identiﬁer fid and index
i(i = 0,...,m) as input to generate m values in the subgroup of quadratic residues
QR .
N
The ﬁrst homomorphic RSA-based signature RRSA can be described as a
tuple (NGen, NSign, NVrfy, Combine) presented in [13].
k
NGen(1 , m, n). The RRSA algorithm takes as input security parameter k, the
?
values of m and n and parameters B and B deﬁned above. It outputs a
pair of keys (vk, sk). The public key vk is (N,e,g ,...,g ) where N is a
1 n
?
RSA composite, e is a public exponent which is a prime larger than mB
13andg ,...,g are generators of thesubgroup ofquadratic residuesQR . The
1 n N
private key sk is d such that ed? 1 (mod ?(N)).
NSign(sk, fid,W). The signing algorithm takes place on the source node. Be-
fore transmitting a ﬁle, the source node partitions the original ﬁleV into
vectors of length n and encodes them into a properly augmented bases
(1) (n) (i) m+n
(w ,...,w ), w ? Z . It then randomly chooses a ﬁle identiﬁer fid
for the ﬁle and applies hash function H to generate m values h ,...,h in
1 m
ﬁeld QR , h = H(i,fid), i = 1,...,m. Finally, the source node computes
N i
the signature ? on each w in subspaceW:
m n
Y Y
v
u
j d
i
? =( h g ) mod N
i j
i=1 j=1
where g ,...,g are parts of the public key vk and h ,...,h are ﬁle-speciﬁc.
1 n 1 m
(i)
The source then transmits the vector w and its corresponding signature
along with the ﬁle identiﬁer fid into the network throughits outgoing edges.
NVrfy(vk, fid, w, ?). To verify a signature ? on a vector w =
(u,...,u ,v ,...,v ). The intermediate node proceeds as follows:
i m 1 n
1. Check the coordinates in the u ’s are positive and smaller than B.
i
?
2. Check the coordinates in the v ’s are positive and smaller than B .
i
3. Retrieve the public key vk and compute h = H(i,fid) for i = 1,...,m
i
usingtheknownhashfunction. Checkthatthefollowingequationholds
m n
Y Y
v
e u j
i
? = h g mod N. (1)
i j
i=1 j=1
4. If all the checks pass, the algorithm outputs 1, or outputs 0.
?
(i)
Combine(vk, fid,{(w ,?,? )} ). Once an intermediate node receives ? in-
i i
1
coming packets and each packet has passed the veriﬁcation check, it ran-
domly chooses ? coe?cients ? ,...,? from Z ={0,...,Q? 1} and then
1 ? Q
P Q
? ?
?
? (i) ? i
computes w = ?w and its corresponding signature ? = ?
i
i
i=1 i=1
mod N.
E?ciency. This RSA-based scheme over integers avoids pairing computations
needed in the signature scheme over bilinear groups and uses small coe?cients(8-
bits) ? chosen from the domainZ ={0,...,Q?1}. This design helps to reduce
i Q
the computational overhead since, in the combine algorithm, the multiplications
arewithsmallintegersandtheexponentsoftheexponentiationsare8-bitsintegers;
14it also reduces the communication overhead when the distance from the source to
the targets doesn’t exceed the value L. Gennaro et al shows that only to choose a
smallintegerQ,suchasQ = 257,isenoughtoallowagoodperformanceandalsoa
gooddecoding probability(the probability that the targetnode can recover the ﬁle
correctly). The signing algorithm requires one full exponentiation and one multi-
exponentiation; theveriﬁcationalgorithmneedsonemulti-exponentiation; andthe
combine algorithm contains one multi-exponentiation and some multiplications
and additions. Each signature is one of the elements inZ .
N
4.2 RSA-Based Scheme in Standard ModelSRSA
We are going to show in detail the RSA-based scheme in standard model(to which
we refer to SRSA, S stands for standard model).
In SRSA construction, a parameter ? is applied to specify the domain I
?
for ﬁle identiﬁers and its relation to M is 2 > M. The set of prime numbers
of exactly (? + 1) bits forms the space I, and each prime number is greater
?
than 2 . The coe?cients in the scheme for linear combination are chosen from
the domain F where the public exponent e is equal to the ﬁle identiﬁer in
e
I, namely, e = fid. Since the source node chooses a ﬁle identiﬁer fid for
each ﬁle and each fid determines the domain of the coe?cients for linear com-
bination,theﬁniteﬁeldsoverwhichlinearcombinationisdonearedi?erentinﬁles.
This precise SRSA scheme is shown in a tuple (NGen, NSign, NVrfy, Com-
bine) as done in [11].
k
NGen(1 , fid, m, n). The SRSArandomly chooses two safeprimep,q oflength
k/2 and computes N =pq. g,g ,...,g ,h ,...,h are chosen at random from
1 n 1 m
?
Z . The security parameter ? is speciﬁed to deﬁne the domainI of the
N
ﬁle identiﬁers. The public key vk is set to (N,g,g ,...,g ,h ,...,h ) and the
1 n 1 m
secret key sk is d such that ed? 1 (mod ?(N)).
NSign(sk, fid,W). The signing algorithm is performed on the source node. On
m+n
(1) (m) (i)
input a vector spaceW?F of the form (w ,...,w ) and each w =
M
(i) (i)
(u ,v ). As speciﬁed before, e is a RSA public exponent and e = fid.
The source chooses an integer s inZ at random and uses its secret key d to
e
compute the signature for each vector w?W.
m n
Y Y
v
u j
s i d
x = (g h g ) mod N.
i j
i=1 j=1
15The signature ? = (s,x) is for the vector w. The source node calculates all
(i)
the signatures corresponding to each vector w ?W and then sends out to
the network through its outgoing edges.
NVrfy(vk, fid, w, ?). On input a vector w = (u ,...,u ,v ,...,v ) and a signa-
1 m 1 n
ture ? =(s,x). The verifying algorithm proceeds as follows.
1. Check that e is an odd number of size ?+1.
2. Check that all the u ’s, v ’s and s are chosen fromZ .
i i e
3. Check that the following equation holds.
m n
Y Y
v
e s u j
i
x =g h g mod N. (2)
i j
i=1 j=1
4. If all the checks pass, the algorithm outputs 1, or outputs 0.
?
(i)
Combine(vk, fid,{(w ,?,? )} ). Once an intermediate node receives ?
i i
1
incoming packets and each packet has passed the veriﬁcation check, it
randomly chooses ? coe?cients ? ,...,? and computes as follows.
1 ?
First, computes
? ?
X X
? (i) ? (i)
w = ? ·w mod e. w = ( ? ·w ?w)/e.
i i
i=1 i=1
? ?
X X
? ?
s = ?s mod e. s =( ?s ?s)/e.
i i i i
i=1 i=1
? ? ?
Let w = (u,v). Then computes
Q
?
?
i
x
? i=1 i
x = mod N (3)
?
?
Q Q
v
u
m n j
s i
g h g
i=1 i j=1 j
? ? ?
Finally, it outputs a new signature ? =(s ,x ).
E?ciency. As the RRSA construction, SRSA avoids using expensive pairing op-
erations. Signing requires one full exponentiation, one multi-exponentiation in do-
mainZ andthe selection of a randomprime number s. The veriﬁcation operation
e
costs oneexponentiation witha primeof(?+1)-bitsandonemulti-exponentiation
with ?-bits exponents. The combining algorithm consists of many arithmetic op-
erations, especially one multi-exponentiation as done in the veriﬁcation algorithm.
Each signature consists of an element in Z and an integer s? Z . Notice that
N e
the communication overhead is not going to increase as the (mod e) operation in
combining algorithm; this allows no limitation in the distance from the source to
the targets.
164.3 SchemeoverBilinearGroupinRandomOracleRCDH
The ﬁrst homomorphic network coding scheme over bilinear groups is proposed
by Boneh et al. in [7]; it has proved secure under the co-CDH assumption(to
which we refer to RCDH).
The signature scheme can be described as a tuple (NGen, NSign, NVrfy,
Combine) as done in [7].
k
NGen(1 , m, n). On input a security parameter k, and two integers m, n. Do
the following:
? ?
1. Generate a bilinear group tuple ? = (G,G,G ,e,?) such that G, G
T
k
and G are three bilinear groups of prime order p > 2 satisfying a
T
?
bilinearmap? :G?G ?G . Randomlypickgeneratorsg ,g ,...,g ?
T 1 2 N
? ?
G\{1} and g ?G\{1}.
? s
2. Randomly choose s inF , and let ? be (g ) .
p
3. Let denote with H :Z?Z?G a hash function.
4. Output a prime p and a key pair (vk, sk) where the public key vk is
?
(?,H,g ,...,g ,g,?), while the secret key sk is s.
1 N
NSign(sk, fid,W). On input a secret key sk, a ﬁle identiﬁer fid, and a vector
(1) (m) (i) m+n
spaceW = (w ,...,w ) where w ? F . It outputs a signature on
p
vector w?W by computing
m n
Y Y
v
j
u s
i
? = ( H(fid,i) g ) .
j
i=1 j=1
The source node computes all signatures for the vectors and sends out the
vectors and their corresponding signatures along with the ﬁle identiﬁer to
the network through its outgoing links.
NVrfy(vk, fid, w, ?). Given a vector w = (u ,...,u ,v ,...,v ), and a signature
1 m 1 n
?. It outputs 1 if the following equation holds
m n
Y Y
v
j
? u
i
e(?,g ) =e( H(fid,i) g ,?), (4)
j
i=1 j=1
otherwise outputs 0.
?
(i)
Combine(vk, fid,{(w ,?,? )} ). We assume that the intermediate node re-
i i
1
(1) (?)
ceives u incoming packets w ,...,w and every packet has passed the ver-
iﬁcation check. It then randomly chooses u coe?cients ? ? F for linear
i p
17P Q
? ? ?
? (i) ? i
combination. Thealgorithmcomputesw = ?·w and? = ?
i
i=1 i=1 i
? ?
and outputs a pair (w ,? ).
E?ciency. The RCDH construction has constant-size public key and constant-
size per-packet signatures which makes the scheme suited for network coding ap-
plications. The signing algorithm requires one full exponentiation and one multi-
exponentiation. The veriﬁcation algorithm needs two pairing computations and
one multi-exponentiation. Each signature is one of the elements inG which means
that we can choose as short as possible group elements in G to reduce the com-
munication overhead.
4.4 SchemeoverBilinearGroupinStandardModelSSDH
This sectionisgoingtodiscuss thehomomorphic network codingsignaturescheme
based on q-SDH in standard model[11](to which we refer to SSDH).
This scheme is adapted from the one proposed by Hofheinz and Kiltz [17]
which is built on the concept of Programmable Hash Functions. In SSDH
construction, all operations are deﬁned over Z where prime p is speciﬁed by
p
the key generation algorithm; for instance, the (mod p) operation in combining
?
algorithm. File identiﬁers are elements inZ .
p
The precise signature scheme is a tuple (NGen, NSign, NVrfy, Combine) as
shown in [11].
k ?
NGen(1 , m, n). Generate a bilinear group tuple ? = (G,G,G ,e,?) such that
T
? k ?
G,G,G have prime order p > 2 . G,G,G are three bilinear groups
T T
? ?
satisfying a bilinear map ? : G?G ? G and g and g are generators of
T
?
G,G respectively. Do the following:
? z
1. Randomly choose an integer z in spaceZ and let Z =(g ) .
p
2. Pick random elements h,h ,...,h ,g ,...,g from groupG.
1 m 1 n
3. Output a key pair (vk,sk) where the public key vk is set as
?
(p,Z,h,h ,...,h ,g,g,g ,...,g ) and the secret key sk is z.
1 m 1 n
NSign(sk, fid,W). The signing algorithm takes as input a ﬁle identiﬁer fid
?
randomly chosen from Z , and a properly augmented vector basisW =
p
(1) (m) m+n
(w ,...,w ) whereW?F . It chooses a random number s?Z and
p
p
computes the signature on w
m n
Y Y
1
v
s u j
i
z+fid
x = (h h g ) .
i j
i=1 j=1
18Then the signature for vector w is ? = (x,s). The source node calculates
m signatures on m vectors and transmits the signatures associated with
corresponding vectors into the network.
NVrfy(vk, fid, w, ?). The algorithmveriﬁes a signature? onthe corresponding
vector w =(u ,...,u ,v ,...,v ) by checking if the following equation holds:
1 m 1 n
m n
Y Y
v
? fid s u j ?
i
e(x,Z·(g) ) =e(h h g ,g). (5)
i j
i=1 j=1
It outputs 1 when the equation is satisﬁed, otherwise outputs 0.
?
(i)
Combine(vk, fid,{(w ,?,? )} ). We assume that the intermediate node re-
i i
1
(1) (?) (i) m+n
ceives ? incoming packets w ,...,w where w ?F and every packet
p
has passed the veriﬁcation check. It then randomly chooses ? coe?cients ?
i
for linear combination fromF and computes
p
? ?
Y X
? ? ?
i
x = x . s = ? ·s mod p.
i i
i
i=1 i=1
? ? ?
Finally, it outputs ? =(x ,s ).
E?ciency. EachsignaturecontainsanelementingroupGandanumberinZ . A
p
signing operationneeds onefullexponentiation inGandone multi-exponentiation
in G and the veriﬁcation algorithm requires two pairing computations and one
multi-exponentiation in G in addition to two exponentiation(one in G and the
? ?
otheroneinG)andtwomultiplications(oneinGandtheotheroneinG). Wewill
see later that the four extra group operations in contrast to RCDH construction
are the main cause of the time di?erence of processing overhead between RCDH
and SSDH.
4.5 Summary and Comparison
After introducing four secure homomorphic signature schemes, we are going to
make a comparison of the schemes over di?erent oracle models from a theoretical
perspective.
RSAGroup consists of the RSA-based scheme in random oracle by Gennaro
et al.[13] and the scheme in standard model by Catalano et al. [11]. In addition
to the di?erent oracles they use, the two schemes are distinct in three aspects as
discussed in [11]. First, in random oracle model, the RSA-based scheme is to have
a better performance only when the distance between the source and the targets
19is not too large(say, up to 20 to 30 hops); while, in standard model, the operation
(mod e) in the combining algorithm makes the value of the vector coordinate
always less then e which allows no limitation in the path length. Second, the size
of the public key in SRSA scheme is linear in (m+n) in contrast to the constant
key size in RRSAscheme since some parameters aregenerated ontheintermediate
nodes using random oracle. Finally, the signature size and the time needed for
signing and veriﬁcation algorithms in these two schemes are comparable to some
extent. Thelastpointconcernsthee?ciencywhichwewilllookintointheproject.
BilinearGroup contains the scheme based on the co-CDH assumption in random
oracle in [7] by Boneh et al. and the other one under the q-SDH assumption in
standard model in [11] by Gennaro et al.. The combining algorithm in SSDH
construction hastheadvantageof avoiding thecommunicational overhead growing
without limitation by (mod p) when the distance becomes longer. However, to
use standard oracle, the SSDH scheme has to do two extra exponentiations(in G
? ?
andG) and two extra multiplications(in G andG) in the veriﬁcation algorithm;
this has resulted in the extra computational overhead as the operations which
involve bilinear groups are normally costly.
205 Communication Models
In this chapter, we assume that the intermediate nodes have enough memory
space and computing power to do expensive computations. We are going to ﬁrst
give a brief introduction of the communication models of network coding and
homomorphic signature and then compare them according to the models given.
5.1 Network Coding
According to Figure 1, when a ﬁle is to be transmitted, it is divided into m
blocks and each block is represented as a vector; the source node A then calls the
function encode() to prepend the unit vector of length m to each vector. Once the
intermediate node B receives ? incoming blocks, it ﬁrst starts vry NC() to check
the linear independence of the received blocks and discards the blocks that don’t
pass the check; and then node B runs com NC() to do a linear combination of the
valid blocks to a new one. Figure 1 shows that the computational overhead on the
intermediate node is caused by vry NC() and com NC().
Figure 1: Network Coding
5.2 Homomorphic Signature
In homomorphic network coding signature, to transmit a ﬁle, the source node
A starts encode() on the original ﬁle to generate coded blocks, and then calls
vry Sig() to sign those blocks; after that, the node A sends out the coded blocks
alongwiththesignatures throughitsoutgoingedges. Whentheintermediate node
21B receives ? blocks, it ﬁrst checks the linear independence of the received blocks
by applying vry NC() and then continues to validate the signatures by running
vry Sig() function; ﬁnally it combines the blocks that pass the veriﬁcation check;
that is, it calls com NC() to combine the information part of the blocks and
com Sig() to combine the signatures. Notice that, in addition to the operations
doneinnetworkcoding,theveriﬁcationalgorithminhomomorphicsignatureneeds
tocheckthevalidityofthesignatureandthecombiningalgorithmneedstocombine
the signatures associated with the valid blocks. Here, we refer to two operations
com NC() and com Sig() to combine(). The processing delay in homomorphic
network coding is caused by vry NC(), vry Sig() and combine().
Figure 2: Homomorphic Signatures
5.3 Summary and Comparison
From the above illustrations of the communicational models, we can see that both
network coding and homomorphic signature incur the computational overhead
in transit. Though, on the intermediate nodes, network coding only performs
two operations, vry NC() and com NC(), it faces the challenge of pollution
propagation. Homomorphic network coding signatures are designed to deal with
the drawbacks of network coding; nonetheless, it results in expensive crypto-
graphic overhead because of four extra operations, Sign(), vry NC(), vry Sig()
and com Sig(). The latter three operations will lead to computational overhead
while the ﬁrst one will not result in overhead since the signing operation is only
carried out on the source node.
22In later chapters, we will see that in network coding, the processing time
of vry NC() and com NC() are negligible when compared to the overhead in
homomorphic signature schemes since these two computations usually require
multiplications and additions that are not expensive. However, in homomorphic
signatures, two extra operations done on the intermediate nodes, vry Sig()
and combine(), require complex cryptographic computations(multiplication,
exponentiation and modular) which will lead to heavy computational overhead
and then a?ect the performance of a signature scheme.
To conclude, we can learn that homomorphic signature will cause expensive
computational overhead when compared to the network coding while the security
level it obtains is higher than that of network coding. And to achieve the
purpose of the project, that is, to compare the computational overhead of the
schemes in random oracle/standard model, our focus is on the three extra
operations(vry NC(), vry Sig() and combine()) done in homomorphic signature
to see how large the time di?erence of each operation of the schemes in the same
group is.
236 Implementations
To compare two groups(RSAGroup and BilinearGroup) mentioned above sepa-
rately from an experimental perspective, we implement four signature schemes on
Ubuntu11.10whichisinstalledinworkstation8.0virtualmachineonanIntelCore
i5 processor(2.3GHZ, 4GB). GNU Multiple Precision Arithmetic Library(GMP)
[20] is used to deal with the large integers and OpenSSL [23] is for implementing
the random oracle. For the implementation of pairing operation, we choose the
Pairing-Based Cryptography(PBC) [21] library which is built on the GMP library.
GMP library is one of the popularly-used big number libraries which provides
arbitrary precision arithmetic. This library is designed to be as fast as possible
and said to be the fastest of all big number libraries so far. The high speed has
made it a good choice for cryptographic applications, especially network coding
schemes inwhiche?ciency isoneofthemainrequirements. Toimplementpairing,
routines like elliptic curve arithmetic, elliptic curve generationand pairing compu-
tation are provided in PBC library and by using the functions available in GMP
library, PBC library is able to achieve reasonable pairing time. An additional ad-
vantage of PBC library is when implementing pairing operations, we don’t need
to know the precise knowledge of elliptic curves since the API is abstract enough
for users with an elementary background of pairings. OpenSSL is an open source
toolkit to implement SSL/TCL security protocol and various hash functions are
available as well; SHA2 in OpenSSL is applied to instantiate the random oracle.
In four schemes, the upper bound of coordinates of the initial vectors M is set
t
to (2 ?1) meaning that the length of the speciﬁed coordinates is no more than
tbits. Thenumberofblocksaﬁleisdividedintoissettomandeachblockconsists
of n coordinates before prepended with the unit vectors. Accordingly, the genera-
t
tion size is at most (2?1)?m?n. In general, the values of M and m are ﬁxed in
advance by the network coding applications; therefore, to transmit a ﬁle, we can
playwiththevalueofntoletM andmmeettheconditionssetbytheapplications.
This chapter is going to introduce the implementation details of four schemes;
ﬁrst, we introduce the Gaussian Elimination and then two RSA-based schemes
followed by two bilinear-based schemes.
6.1 Gaussian Elimination
In linear algebra, Gaussian elimination is a standard algorithm for solving simul-
taneous linear equations; it can also be used to compute the determinant of a
matrix or to ﬁnd the rank of a matrix. Two processes are contained in Gaussian
24elimination, ’Forward Elimination’ and ’Back Substitution’. Forward Elimination
is aimed at transforming a matrix into the form of triangular or echelon or a de-
generate equation by applying elementary row operations; a degenerate equation
implies that there is no unique solution for the set of functions; whereas the trian-
gular or echelon forms indicate that there is a unique solution. Back Substitution
is used to solve the resulting equations from Forward Elimination to obtain the
solutions. Another popular application of Gaussian elimination is to check the
linear independence of a family of vectors. Linear independence of a set of vectors
is, in linear algebra, that none of the vectors can be expressed as a combination of
other vectors in the same set. As mentioned, in network coding, the intermediate
nodes have to check the linear independence of received blocks and discard the
blocks that depend on the others by calling vry NC(). In our experiment, we use
the algorithm Gaussian elimination to verify linear independence.
The implementation of vry NC() can be shown by using the following pseudo
code. The main idea is to apply the ﬁrst process of Gaussian elimination, Forward
Elimination, to reduce the matrix formed by the received blocks(each row repre-
sents one block) and then check whether there exists a row with every components
set to 0; if there doesn’t exist a row with all coordinates set to 0, the vectors
are linearly independent and the intermediate nodes would store these blocks for
further modiﬁcation.
if(row>column){
Linear Dependence.
Return.
}else{
for(i=0;i< column;i++){
/* Find the row with the largest ﬁrst number */
FindMaxRow();
/* Swap the maxrow and ith row */
Swap();
/* Search row with all coordinates set to 0 */
if(Exit one row with all zeros){
Linear Dependence.
}else{
Linear Independence.
}
}
}
25The above code shows the implementation of vry NC(). The idea is the same
in the four schemes we examine in our project; however, according to the alge-
braic setting the schemes deﬁned over, the schemes in the same group(RSAGroup
or BilinearGroup) have the identical implementations of vry NC(). This implies
that the vry NC() algorithms in the same group will not cause the time di?er-
ence of the schemes. Consequently, to compare the schemes in the same group in
terms of computational overhead, we can safely leave the comparison of vry NC()
algorithms and concentrate on vry Sig() and combine().
6.2 Implementations ofRRSA andSRSA
This section isgoing togive the implementation details oftwo RSA-based schemes
in RSAGroup. Given the identical implementations of vry NC() in two schemes,
the focus is on vry Sig() and combine()
6.2.1 Implementation Comparisons
Two tables, Table 1 and Table 2, illustrate the scope of parameters concerned
with two RSA schemes in random oracle and standard models respectively. In
both schemes, the value of t is set to 192 which means that the magnitude of the
192
components in the initial vectors is no more than (2 ? 1) and the size of the
ﬁle identiﬁer fid is 193bits. In RRSA scheme, the distance L is 20 hops and the
coe?cients are randomly chosen fromZ (Q is set to 257 in our implementation);
Q
L
the public exponent e is larger than m(mQ) M as speciﬁed in the scheme def-
inition. In SRSA model, the coe?cients are from the ﬁeld F and e is 193bits
e
which is equal to fid and deﬁned by one of the security parameters ?. Notice
that the public exponent e in RRSA will change with m and is larger than e in
SRSA. Nonetheless, this is not going to a?ect the time di?erence of computational
overhead in two schemes since public exponent e is only used on the source node
for signing algorithms.
Table 1: Parameters of RRSA
Parameters M q fid L e ?
i
193 L
Range 192bits =257 < 2 = 20 >m(mQ) M ?Z
Q
From these two tables, we notice that two RSA-based schemes have the same size
of M and fid; and other parameters are chosen according to the deﬁnitions of the
schemes. In our experiments, we will change the value of m and n respectively to
see the variation of the processing time for vry Sig() and combine().
26Table 2: Parameters of SRSA
Parameters M e fid ?
i
Range 192bits 193bits 193bits ?F
e
Our project will also examine how the security parameter k a?ects the crypto-
graphic overhead of two schemes. The value of k is set to 512 and 1024 and Table
?
3 shows the other parameters which depend on the value ofk. Notice thatg ’s/h s
i
i
are generated on the source node and send out with the information in standard
model; whereas in the random oracle model, onlyg ’s are generated at ﬁrst, mh ’s
i i
are constructed on the ﬂy on the intermediate nodes using random oracle.
Table 3: Parameters of Two RSA Scheme
Parameters k N p/q g/h
i i
size(bits) 1024 1024 512 1024
size(bits) 512 512 256 512
6.2.2 Parameter Generations
It is worth mentioning how we choose the parameters g ’s and h ’s in RRSA and
i i
SRSA. Before that, we ﬁrst illustrate the deﬁnition of quadratic residue and then
examine two theorems which serve as theory evidences.
Quadratic Residue. An integer a?{0,...,N? 1} is in QR if and only if
N
2
there exists an integer x such that x ?a(mod N).[19]
Theorem 1. If G is a group of prime order p, then G is cyclic and all ele-
ments inG except the identity are generators ofG.[19]
Theorem 2. N is a composite number with two prime multipliers p and q, and
y = (y ,y )(y is the least common multiple of y and y ). If y is a quadratic
p q p q p
residue modulo p and y is a quadratic residue modulo q, then y is a quadratic
q
residue modulo N.[19]
RRSA scheme. In RRSA construction, g ’s are generators of the subgroup of
i
quadratic residue QR . According to the two theorems above, we generate g ’s as
N i
follows:
2
1. Randomly choose r fromZ and compute r =r (mod p); (Theorem 1)
1 p 1
1
272
2. Randomly choose r fromZ and compute r =r (mod q); (Theorem 1)
2 q 2
2
3. Compute g = (r ,r ). (Theorem 2)
i 1 2
h ’s are in the domain QR which need to be calculated on the intermediate
i N
nodes. Since the output of a hash value is a random number, we need to do extra
calculation to map the random outputs into QR . We generate h ’s as follows:
N i
1. Compute r = SHA2(fid+i);
2
2. Compute h =r (mod N) to map the hash value into QR .
i N
?
SRSA scheme. In SRSA construction, g ’s and h ’s are random numbers inZ
i i
N
and they are selected according to the following steps:
1. Randomly choose r fromZ ;
1 p
2. Randomly choose r fromZ ;
2 q
3. Compute g/h = (r ,r ) (the least common multiple of r and r ).
i i 1 2 1 2
6.3 Implementations ofRCDH andSSDH
In this section, we are going to discuss the implementation details of two bilinear-
based schemes.
6.3.1 Implementation Comparisons
Two bilinear-based signature schemes apply asymmetric pairing available in PBC
library. There are seven kinds of pairings in PBC library, from Type A to Type
G; among which, Type B and Type C pairings haven’t been implemented. Type
A results in the fastest pairing but is only suitable for symmetric pairing. In order
to do e?cient asymmetric pairing, we feed Type D parameters into the pairing al-
gorithm. Type D pairing is constructed on curves of degree 6 and has the order of
a prime number or a prime multiplied by a small constant; complex multiplication
method is applied to generate Type D curves. In Type D pairing, the elements in
groupG are expressed in a small size, normally larger than 170bits; and by using
?
a trick, the size of elements in group G can be only three times longer(generally
?
the size of G should be six times longer without the trick used in PBC library).
The other types of pairing are so costly that they are not recommended in the
time-critical applications.
28There are a few Type D parameters provided and they are represented as triples,
the discriminant, the size of the elements in G and the size of group orders. In
our experiment, we use the parameter d277699-175-167 which indicates that the
primeordersofthreebilineargroupsareofsize167bitsandthesizeoftheelements
in G is 175bits. Therefore, we set the size of p(as deﬁned in the schemes) to be
167bitsaswell asthesecurity parameterk; pandk areofthesame size butshould
k
conform to the condition p > 2 . Then t can be up to 167 as the coordinates of
vectors should be in F . As the type of the pairing indicates, the element size of
p
?
groupG is accordingly set to 175bits and the element size of the second groupG
is tripled, 525bits. The scheme in random oracle needs to calculate m h ’s on the
i
intermediate nodes. As shown in Table 4, the ﬁle identiﬁer fid in random oracle
?
is exactly of kbits; however, fid can be chosen from the ﬁeldZ ; for simplicity, we
p
assume that the size of fid is exactly kbits in both schemes.
Table 4: Parameters of Bilinear Groups
Parameters k p G G fid
1 2
RCDH 167bits 167bits 175bits 525bits 167bits
?
SSDH 167bits 167bits 175bits 525bits ?Z
p
We notice that both bilinear-based schemes apply the same size of M and are
using the same type of pairing with the same parameter set. The same as the
comparisons in RSAGroup, we will check how the computational overhead varies
withmandnrespectively. However, we arenotgoing to examine how thesecurity
parameterk a?ectstheprocessingoverheadoftwoschemes. Asknown, pairingisa
time-consuming operation and even in a highly optimized curve like BN curve[3],
the time needed for one pairing operation is also 20 times longer than that for
exponentiation. Therefore, to apply a pairing-based network coding scheme, a
pairing with e?cient performance is required. In PBC library, we can see from
the above analysis that Type D is the most attractive one for our implementation.
Typically, in a Type D pairing, the size of the element inG is larger than 170bits;
so we choose the set of parameters d277699-175-167that just meets this condition
to achieve a certain security level. d277699-175-167 is the parameter set already
generated and stored in the PBC ﬁle directory.
6.3.2 Parameter Generations and Library Functions
Here, we give the instantiation of random oracle and discuss some programming
functions in PBC library.
29Hash Value Generation. We have mentioned that, in RCDH construction,
mh ’s are established on the ﬂy. These values, as deﬁned, are in groupG and this
i
has raised the problem of how to map the hash values into the group G. In our
experiment, we use the hash function SHA-256 in OpenSSL to generate the hash
value; the process is shown as follows:
1. Randomly choose g fromG;
2. Compute r=SHA256(fid+i);
r
3. Compute h =g .
i
Notice that the generation of m hash values are done over the ﬁeld Z and all
p
these results are then treated as the exponents in the exponentiations with the
basis picked up fromG.
Pairing. There are steps to follow when running PBC library to complete one
pairing operation. Several pairing functions are available that may achieve the
same goal, but we only focus on the one we use in our project. To do pairing
computation, we have to initialize the pairing variable at ﬁrst; and then we call
the pairing function
element pairing(element t out, element t in , element t in ).
1 2
?
Thisfunctiontakestwoinputsofelementsin fromGandin fromG andoutputs
1 2
out inG . Based on the platform we implement, one pairing takes approximately
T
5.43ms.
Exponentiation. Another function we have to mention is the one to implement
exponentiation
element pow zn(element t x, element t a, element t n).
n ?
It computes x =a where a can be an element inG orG and n is a value chosen
from a ring or a ﬁeld. We will see later that the function costs approximately
the same amount of time as the pairing operation when the size of the element in
the group where a chosen from becomes large. In our experiment, with the base
?
numbers from group G, one exponentiation takes nearly 6.23ms; while, with the
base numbers from group G, the amount of time is only 0.77ms which is almost
seven times less. Notice that the time for exponentiation with the base numbers
?
inG is comparable to the time for pairing.
?
Multiplication. Compared to exponentiation, multiplication in groups G or G
is not costly
30element mul(element t n, element t a, element t b).
?
Itcomputesx =abwhereaandbcanbechosenfromthebilineargroupsGandG,
rings or ﬁelds. When one scheme needs to do one more multiplication(in groups
? ?
G orG) and one more exponentiation(in groupsG orG) than the other scheme,
the time di?erence of these two schemes is mainly caused by the exponentiation
ratherthanthemultiplication; thisisbecausetheprocessingtimeofmultiplication
is negligible when compared to the time needed for exponentiation.
The discussion of three programming functions in PBC library will support for
our analyses of the experimental results in Chapter 7.
317 Results and Analyses
In what follows we will compare the schemes in two groups(RSAGroup and
BilinearGroup) mentioned above separately from an experimental perspective
to see whether homomorphic signatures in random oracle/standard models are
comparable or not. The comparisons are associated with precise analyses and
followed by a brief summary of this chapter.
Four schemes we describe above apply the method Gaussian Elimination in
vry NC() to validate the linear independence of received blocks. The implementa-
tionsofGaussianEliminationhavebeenexplainedinSection6.1; theexperimental
results demonstrate that the time needed for the vry NC() algorithm depends
on the number of downloaded blocks and the overhead can be neglected when
compared to other algorithms(vry Sig() and combine()). We have found that the
vry NC() implementations of the schemes in RSAGroup or BilinearGroup are
identical; as a result, the processing time for vry NC() can be safely ignored when
comparing schemes in the same group.
Therefore, our comparison will only focus on two algorithms, vry Sig() and
combine(). We assess the vry Sig() algorithm at the targets by measuring
the time for verifying m signatures. For simplicity, the download delay at the
targets is not taken into consideration. The operation combine() is analysed by
calculating the time needed for combining m blocks on the source node.
Notice that we assume the number of downloaded blocks is equal to the
number of blocks a ﬁle is divided into; that is, the number of downloaded blocks
is ﬁxed to m. The variable n is the dimension of the information vectors. In this
chapter, m denotes the number of downloaded blocks on the intermediate nodes.
7.1 Comparisons ofRRSA andSRSA
We will set out to compare two RSA-based schemes in RSAGroup; our analysis
concentrates onexploring howdistinct thecomputationaloverhead oftwo schemes
by observing how the values of m, n and k a?ect the processing time for vry Sig()
and combine(). The implementation details have been illustrated in Section 6.2.
7.1.1 Veriﬁcation Algorithm
This section is going to analyse vry Sig() in RRSA and SRSA. The vry Sig()
algorithms in two schemes consist of the same computational operations, one ex-
ponentiation and one multi-exponentiation. The discussion is based on k = 512.
3225
RRSA
SRSA
20
15
10
5
n=10n=20n=30n=40n=50
Figure 3: Veriﬁcation Overhead(m = 8)
RRSA
40
SRSA
30
20
10
m=8 m=16 m=32 m=64
Figure 4: Veriﬁcation Overhead(n = 10)
Figure 3 and Figure 4 illustrate the processing delay of veriﬁcation algorithms
in two schemes when k is 512. The time required for this operation depends
on the values m and n; we will examine the variation according to these two
values respectively. Figure 3 shows how n a?ects the vry Sig() time when m is
33
processing delay (ms) processing delay (ms)
4.17 4.17
4.21 4.21
8.07
9.13
7.88
8.49
11.45
11.77
16.69
14.78
16.87
14.37
36.43 17.98
36.43 19.96constant(m = 8 in our case; n is changed from 10 to 50 with an increase of 10
every time); whereas in Figure 4, n is constant but m changes (n = 10 in this
case; m is doubled every time).
These two ﬁgures demonstrate a clear feature that the vry Sig() algorithms
in these two schemes take almost the same amount of time when m and n have
the same values. Speciﬁcally, when m and n are set to 8 and 10 respectively,
the veriﬁcation time for the scheme in random oracle is 4.17ms in contrast to
4.21ms in standard model; the time spent is approximately the same. Besides,
we also notice a steady rise in the time needed for vry Sig() in RRSA or SRSA
when the variable in X-axis(m in Figure 3 or n in Figure 4) grows; the feature
worth mentioning is that the time doubles as the number of downloaded blocks
m doubles(see Figure 4). The variation tendency shows that the overhead of the
vry Sig() algorithms depends on the values of m and n.
Analysis. Let us analyse the vry Sig() algorithms in Section 4.1 and Sec-
tion 4.2; they are mainly di?erent in the following two aspects. First, in RRSA,
vry Sig() needs to generate m h ; whereas, in SRSA, these values are set and
i
transferred with the ﬁle blocks. Second, in comparison to Equation (1), Equation
(2) needs to do two extra operations, one is the exponentiation with the exponent
which can be up to 193bits in our case and the other one is the multiplication in
Z . From the experimental results, the excess computations done in RRSA and
N
SRSA require approximately the same amount of time and these computations
are cheaper when compared to the multi-exponentiation operation.
7.1.2 Combining Algorithm
This section gives the comparisons of combine() algorithms in two schemes; as the
same as the vry Sig() comparison, the analysis is based on k = 512.
Results of the implementation illustrate that, in the random oracle model, the
time for combine() is very cheap and far less than the vry Sig() processing delay.
The value of m is the only element that a?ects the combine() time in RRSA and
the time shows a very small increase when m grows. From Figure 5, combine()
takes around 0.66ms on average and the amount of time stays stable when the
value of n changes from 10 to 50 and the value m is ﬁxed to 8; from Figure 6,
combine() costs 0.61ms when vry Sig() takes 4.17ms(in the case m = 8, n = 10),
and the combine time has only a slight rise to 0.92ms(m = 64, n = 10) from
0.61ms when vry Sig() takes 19.98ms. Nevertheless, this is not the case when
it comes to the scheme in standard model where combine() has a noticeable
increase when m or n changes. We notice that the combine time and the increase
345
RRSA
SRSA
4
3
2
1
n=10n=20n=30n=40n=50
Figure 5: Combine Overhead(m=8)
RRSA
SRSA
6
4
2
m=8 m=16 m=32 m=64
Figure 6: Combine Overhead(n=10)
in combine time in standard model are more signiﬁcant than that in random
oracle. For example, combine() in SRSA scheme takes 1.94ms(m =8 and n= 10)
and the time increases to 4.58ms(m = 8 and n = 50) and to 6.37ms(m = 64
and n = 10); in standard scheme, combine() takes 6.37ms while vry Sig() takes
19.96ms when m = 64 and n = 10. The di?erence becomes more obvious when k
is set to 1024 which will be discussed in detail later. In addition, the amount of
35
processing delay (ms) processing delay (ms)
0.61 0.61
1.94 1.94
0.64
0.71
2.49
2.48
0.64
3.32
0.72
0.74
3.85
3.58
0.92 0.66
6.37 4.58time in standard model increases as more blocks are downloaded(shown in Figure
6) and is elapsed as the dimension n grows (shown in Figure 5).
Analysis. Notice that vry Sig() brings no di?erence when comparing the
computational overhead of two RSA-based schemes in random oracle/standard
models. In the random oracle model, one combine() operation contains multipli-
cations with 8-bit coe?cients and exponentiations with 8-bit exponents; small
coe?cients make the computations less expensive. However, in standard model,
thecoe?cients chosen canbeup to193bits inourimplementation which aremore
than 30 times than that in random oracle; and the combine() algorithm needs
more cryptographic computations. We ﬁnd that among those extra computations
in combine() algorithm, the multi-exponentiation in Equation (3) in Section 4.2
is the most costly one; and it is the main cause of the time di?erence of the two
combine() algorithms.
7.1.3 Security Parameter k
The above discussion is focused on k = 512. In our implementation, we
change the value to 1024 and observe the same variation tendency discussed in
Section 7.1.1 and Section 7.1.2. We also notice that the time di?erences are
magniﬁed when k becomes larger. We will examine how the security param-
eterk a?ectstheprocessing timeforvry Sig()andcombine()inrespective scheme.
70
k=512
k=1024
60
50
40
30
20
10
n=10n=20n=30n=40n=50
Figure 7: Veriﬁcation Overhead(m =8) in RRSA
36
processing delay (ms)
4.17
14.06
8.07
26.69
11.45
38.81
14.78
50.29
17.98
61.6870
k=512
k=1024
60
50
40
30
20
10
n=10n=20n=30n=40n=50
Figure 8: Veriﬁcation Overhead(m =8) in SRSA
Figure 7 and Figure 8 demonstrate the processing delay of the algorithm vry Sig()
in random oracle and standard models according to two distinct k. From the
ﬁgures, we can see that the veriﬁcation time is at least tripled under the same
m and n when k is doubled. The combine algorithm in RRSA scheme depends
on the value of m and is very time-saving even when k is raised to 1024(an
increase from 0.68ms(m = 8, n = 10) to 1.22ms(m = 64, n = 10)); whereas,
in standard model, the combine operation becomes signiﬁcantly expensive.
Figure 9 and Figure 10 illustrate how the combine time varies with the values
of m and n respectively when k is raised to 1024bits. The time for combine()
increases from 4.85ms(m = 8 and n = 10) to 12.80ms(m = 8 and n = 50) and to
18.46ms(m = 64 and n = 10). The same as the vry Sig() algorithm, the combine
time is more than tripled to that when k = 512 under the same m and n. In
a nutshell, as the value k increases, the processing time needed for vry Sig()
andcombine()getslargeraswell asthetimedi?erenceoftwo RSA-basedschemes.
Analysis. We can see from Table 3 in Section 6.2 that when k is dou-
bled, the size of the parameters N, g ’s and h ’s are doubled; for simplicity, the
i i
size of e stays the same when k changes. The increase in the parameters’ size
is the reason why the time for vry Sig() in RRSA and SRSA or combine() in
SRSA is twice more when k is raised to 1024 from 512. These parameters are
important when doing calculations in vry Sig() and combine(). The reason why
the combine time in RRSA has only a slight increase is that there is only one
operation (mode N) which will cause the excess processing time in the combine()
37
processing delay (ms)
4.21
13.9
7.88
25.31
11.77
39.04
14.37
53.78
19.96
61.14algorithm and this operation is in itself not expensive.
14
k=512
k=1024
12
10
8
6
4
2
n=10n=20n=30n=40n=50
Figure 9: Combine Overhead(m=8) in SRSA
k=512
20
k=1024
15
10
5
0
m=8 m=16 m=32 m=64
Figure 10: Combine Overhead(n=10) in SRSA
7.1.4 Summary and Comparison
From what we discussed above, it is noticeable that the overhead di?erences of
RRSA and SRSA are primarily caused by the algorithm combine() since two
38
processing delay (ms) processing delay (ms)
1.94 1.94
4.85 4.85
2.49
2.48
6.76
6.78
3.32
8.98
3.85
3.58
10.8
10.7
6.37 4.58
18.46 12.8schemes take approximately the same amount of time to complete one vry NC()
algorithm and one vry Sig() algorithm. Figure 11 is a combination of the results
shown above when k = 512; it illustrates how the time for vry Sig() and com-
bine() changes according to the values of m and n. Clearly, the RRSAVerify line
and the SRSAVerify line are overlapped meaning that vry Sig() in two schemes
takes generally the same amount of time. The gap between RRSACombine line
and SRSACombine line indicates the time di?erence of two combine algorithms in
random oracle/standard models; we can see that the gap becomes larger when m
or n grows and will be more signiﬁcant when a higher security level(k is set to a
larger value) is required.
RRSAVerify
SRSAVerify
40
RRSACombine
SRSACombine
30
20
10
64
50
32
40
30
16
20
m
n
8
10
Figure 11: Processing Overhead(k = 512)
To conclude, two RSA-based schemes are somewhat comparable in terms of pro-
cessing delay when the values of m, n and k are small; however, computational
overhead becomes markedly expensive when larger k, m and n are used. The
reason is because the time di?erence of computational overhead in RRSA and
SRSA is small with small k, m and n and gets larger when larger k, m and n
are applied. To achieve a more secure scheme by using a larger k, e?ciency is to
be traded; this trade-o? should be assessed according to the speciﬁc applications
where homomorphic schemes are introduced.
39
processing delay (ms)7.2 Comparisons ofRCDH andSSDH
This section is going to make a comparison of RCDH and SSDH in terms of
vry Sig() and combine(); the comparison is based on examining how the time
di?erence of two bilinear-based schemes changes with m and n respectively. The
implementation details have been shown in Section 6.3.
7.2.1 Veriﬁcation Algorithm
Here, we are going to make a comparison of vry Sig() algorithms of these two
schemes over bilinear groups.
0.5
RCDH
SSDH
0.4
0.3
0.2
n=10n=20n=30n=40n=50
Figure 12: Veriﬁcation Overhead(m =8)
Figure 12 and Figure 13 demonstrate how the vry Sig() time changes with m
and n respectively. According to Figure 12, we see that vry Sig() algorithm in
standard model always takes around 52ms longer than that in random oracle
model whatever the value of n is; for instance, when n = 50, the time required
in standard model is 0.43s compared to 0.38s in random oracle which is around
50ms less and the same phenomenon is observed when n is 10, 20, 30 and 40. In
Figure 13, we see the time di?erence of two vry Sig() algorithms doubles as m
doubles. Clearly, when m = 8, the time di?erence(the vry Sig() time in SSDH
subtracts to the vry Sig() time in RCDH) is 50ms which is doubled to 100ms
when m = 16 and then to 170ms(m = 32) and 440ms(m = 64). Additionally,
the time needed for vry Sig() in both RCDH and SSDH shows a steady increase
when the value of m or n increases. We ﬁnd that the time doubles when the
40
processing delay (s)
0.14
0.19
0.2
0.25
0.26
0.31
0.32
0.38
0.38
0.43number of downloaded blocks m doubles; in Figure 13, vry Sig() takes 1.14s to
verify 64 blocks in random oracle and this number is nearly twice that of the
value 0.59s which is the time for verifying 32 blocks.
1.8
RCDH
1.6
SSDH
1.4
1.2
1
0.8
0.6
0.4
0.2
m=8 m=16 m=32 m=64
Figure 13: Veriﬁcation Overhead(n =10)
Analysis. We now analyse the operation di?erences between two veriﬁcation
algorithms. Both veriﬁcation algorithms consist of one multi-exponentiation and
two pairings. In RCDH, vry Sig() needs to compute m h on the intermediate
i
nodes; whereas, in SSDH, the initialisation of m h is done on the source node
i
?
but two multiplications (in G and G respectively) and two exponentiations (in
?
G andG respectively) are required to complete the veriﬁcation procedure(this is
shown from Equation (4) in Section 4.3 and Equation (5) in Section 4.4).
In Figure 14 and Figure 15, we refer m hash mappings to HashMapping
and four mentioned group operations to GroupAlgo. From Figure 14, we learn
that GroupAlgo is much more expensive than HashMapping. When m = 8, the
time needed for HashMapping is approximately 6.79ms; while, under the same
condition, GroupAlgo takes about 52.57ms, which is 45.78ms longer. Besides,
Figure 14 shows that the amount of time for GroupAlgo grows more signiﬁcantly
than that of HashMapping. Precisely, the HashMapping time has an increase of
41.35ms(from 6.79ms(m = 8) to 48.14ms(m=64)) in contrast to 418.23ms(from
52.57ms(m = 8) to 470.80ms(m = 64)) in GroupAlgo. Figure 15 shows the
processing di?erence between GroupAlgo and HashMapping when m has various
values; this ﬁgure is constructed based on Figure 14. The time gap doubles
when the value of m doubles; the time di?erence is 45.78ms when m = 8 and
41
processing delay (s)
0.14
0.19
0.28
0.38
0.59
0.76
1.14
1.58increases to 100.75ms when m = 16, and then continues to extend to 198.67ms
and 422.66ms when m = 32 and m = 64 respectively. In our experiment, it is
noticeable that the block numbers m is the only element that inﬂuences the time
di?erence between HashMapping and GroupAlgo.
HashMapping
500
GroupAlgo
400
300
200
100
m=8 m=16 m=32 m=64
Figure 14: Processing Overhead(n=10)
500
400
300
200
100
0
m=8 m=16 m=32 m=64
Figure 15: Time Di?erence(n=10) of HashMapping and GroupAlgo
42
processing delay (ms) processing delay (ms)
6.79
45.78
52.57
12.39
100.75
113.14
25.35
198.68
224.02
48.14
422.66
470.8Here, we check which operation in GroupAlgo contributes to the time di?erence.
The focus is on two exponentiations since, relatively speaking, two multiplications
?
are very cheap. We have mentioned that the size of the elements in G is two
? ?
times longer than that in G(175bits in G and 525bits in G). As discussed in
Section 6.3.2, to do an exponentiation using the function element pow zn() will
?
take a longer time if the base is set to the element inG; from the experiment, one
?
exponentiation with the base numbers in G costs 6.23ms on average in contrast
to 0.77ms with base in G. In our project, the measurement of vry Sig() is to
verify m blocks and one vry Sig() in SSDH has to do one extra exponentiation in
?
G; if we set m to 8, it turns out that 8 exponentiations will spend 49.84ms which
occupies around 94.81% in 52.57ms, the time to complete 8 vry Sig() in SSDH.
Clearly, this computational di?erence of GroupAlgo and HashMapping has
led to the di?erent processing delay of the vry Sig() algorithms in two bilinear-
based schemes. Figure 15 which illustrates the time di?erence of HashMapping
and GroupAlgo can be used to demonstrate the overhead di?erence of two
veriﬁcation algorithms.
7.2.2 Combining Algorithm
In what follows we consider the combine() overhead in these two bilinear-based
schemes.
RCDH
25
SSDH
20
15
10
5
0
n=10n=20n=30n=40n=50
Figure 16: Combine Overhead(m=8)
43
processing delay (ms)
22.31
22.92
22.04
21.23
22.81
21.4
22.44
22
22.54
22.51RCDH
200
SSDH
150
100
50
m=8 m=16 m=32 m=64
Figure 17: Combine Overhead(n=10)
Figure 16 shows that combine time doesn’t depend on the value of n because
combine() takes about 22ms(m = 8) whatever the value of n is. In Figure 17, we
notice that, in both schemes, the overhead doubles as the number of downloaded
blocks m doubles; for instance, in RCDH, combine() costs 22.31ms when m = 8
and the time is doubled to 46.76ms when m = 16 and then to 91.84ms and
179.03ms when m = 32 and m = 64 respectively; this phenomenon can also be
observed in SSDH. A common feature in Figure 16 and Figure 17 is that the
combine() algorithms have approximately the same amount of processing delay
when m and n are set to the same values. When m = 64 and n = 10, the RCDH
schemes takes 179.03ms to complete one combine() operation; under the same
conditions, the amount of time is 176.27ms in SSDH which is close to the value
179.03ms.
Analysis. When we examine the combine() algorithms in Section 4.3 and
Section 4.4, we ﬁnd that the computations in both constructions depend on the
number of downloaded blocks m, while they don’t depend on the dimension of
information parts of the vectors n. Besides, the signature in SSDH contains two
parts x and s; the signature in RCDH scheme doesn’t contain the second part.
As a result, in standard model, combine() needs to do the combination of s part
additionally; and it turns out that these computations in F are so cheap that
p
they can be neglected. Therefore, combine() will not bring an overhead di?erence
to these two schemes in di?erent oracle models.
44
processing delay (ms)
22.31
22.92
46.76
47.74
91.84
90.16
179.03
176.27RCDHVerify
SSDHVerify
RCDHCombine
SSDHCombine
1,400
1,200
1,000
800
600
400
200
50
40
64
30
32
20 n
16
m
8
10
Figure 18: Processing Overhead
7.2.3 Summary and Comparison
From what we discussed above, it is noticeable that the overhead di?erences
of two bilinear-based schemes in random oracle/standard model are primarily
caused by the algorithm vry Sig() since two schemes take approximately the
same amount of time to complete one vry NC() and one combine(). Figure 18
works as a combinational result of the above discussion. From Figure 18, we
can see that the RCDHCombine line and the SSDHCombine line are overlapped
meaning that both constructions take approximately the same amount of time to
ﬁnish one combine operation; while the gap between the RCDHVerify line and
the SSDHVerify line shows the time di?erence of these two vry Sig() algorithms.
Let us see the right part of the RCDHVerify and SSDHVerify lines which shows
45
processing delay (ms)the change when m = 8 and n is set to di?erent values; these two parts of lines
are parallel and this indicates that the vry Sig() time gap doesn’t change with
the value of n. The left part illustrates the variation when n = 10 and m is set
to di?erent values; clearly, the gap between two lines becomes bigger when m
increases.
In conclusion, two bilinear-based schemes are somewhat comparable in terms of
the communicational overhead when m and n are small; whereas, they become
incomparable when the values of m or n gets larger. This is because one of the
?
four extra operations in bilinear groups, the exponentiation in G, has made the
time di?erence of computational overhead of these two schemes incomparable,
especially with larger m and n.
7.3 Summary
As presented, our purpose is to investigate the computational overhead of
homomorphic network coding signature schemes in random oracle/standard
model to see whether they are comparable. To achieve this goal, we choose
four homomorphic schemes and separate them into two groups(RSAGroup and
BilinearGroup) and compare the processing delay of the schemes in each group.
From the above analysis, we conclude that the computational costs on the
intermediate nodes in di?erent oracle models are somewhat comparable when the
generation size and the security parameter k are small and the overhead becomes
incomparable when the values of m, n and k become larger. The ’somewhat
comparable’ is under the condition that a certain amount of time di?erence
between the random schemes and the standard schemes is tolerable. A more
detailed explanation will be shown in Section 8.1.
To avoid using a random oracle, we know from the above analysis that the
RSA-based scheme in standard oracle would be preferred in contrast to the
bilinear-based scheme in standard model. This is because pairing computation
is very expensive as well as the exponentiation with the base chosen from the
bilinear group of large element size. However, RRSA can only be applied in the
circumstances that the ﬁle is with a decent size and the security parameter k
is moderate; the larger the ﬁle is, the worse the performance will be. For the
question that of what size a ﬁle can be qualiﬁed asdecent andwhatk is moderate,
it depends on the speciﬁc homomorphic scheme used and the applications.
468 Conclusions and Evaluations
8.1 Conclusions
Linear network coding, as an alternative to traditional network coding, provides
the advantages of high throughput and better network performance. However, lin-
ear network coding faces the challenge of pollution attack which may totally mess
up the e?ort of sending ﬁles. To combat this attack, many countermeasures have
been proposed, including information-theoretic approaches and cryptographic
approaches. We focus on the homomorphic network coding signature which is one
of the cryptographic approaches.
As mentioned, the di?culty of ﬁnding an appropriate hash function has
made a theoretical secure cryptographic scheme in random oracle insecure when
putting the scheme into practice. The challenge has led to the research of our
project, that is, to ﬁgure out whether homomorphic signatures in standard model
are as e?cient as the ones in random oracle in terms of cryptographic overhead
on the intermediate nodes; if this is the case, instead of the random oracle
signature, the standard signature would be the ﬁrst choice. To achieve the goal,
we choose and compare the schemes over the same algebraic setting in di?erent
oracle models. From the existing signatures in the previous works, we select four
schemes, the ﬁrst two(the schemes in random oracle model [13] and standard
model [11] respectively) are built on RSA assumption and the other two(the
schemes in random oracle model [7] and standard model [11] respectively) are
deﬁned over bilinear groups.
We observe that Catalano et al. brieﬂy compare the e?ciency of these four
schemes from two theoretical aspects in [11]. One is the comparison of the
communicational overhead of the schemes; the signature scheme in random oracle
has cheaper communicational overhead than the scheme in standard model as the
former one has public key of constant size, however, the size of the public key in
the latter case is linear in the dimension of blocks. The other one is to compare
the processing overhead of two algorithms(signing and veriﬁcation algorithms) in
those schemes; as shown, the time needed for these two operations is comparable
in random oracle/standard models in some senses.
Our work focuses on two operations(the veriﬁcation of signatures and the
combination) in four schemes from an experimental perspective. The results
output from the four implementations are used as statistical evidences for the
comparisons. Based on the statistics, we have found that (1) two RSA-based
schemes are not comparable because of the combine operation and (2) two
47bilinear-based schemes are not comparable because of the veriﬁcation of signa-
tures; besides, we have seen that the time di?erence is getting signiﬁcant when the
values of m, n or k increase. To emphasize, the number of a ﬁle is divided into m
and the magnitude of the coordinates in initial vectors M are established by the
speciﬁc network coding application; once the application is chosen and the size of
the ﬁle to be delivered is known, we can adjust the value of n to let m and M in
the predeﬁned domains. Normally, in a network coding scheme, if the number of
the blocks stored on the intermediate nodes exceeds the number of blocks a ﬁle is
divided into, the nodes will discard extra incoming blocks that have the same ﬁle
identiﬁersincetheextrablockswillnotpasstheveriﬁcationoflinearindependence.
There are three aspects we need to mention which concern about how the
randomoracle/standardmodelsa?ecttheperformanceofnetworkcodingschemes.
First, strictly speaking, the homomorphic network coding signature schemes
in random oracle/standard models are not comparable especially with larger
m, n and k(m here is the number of downloaded blocks and n and k are as
deﬁned above). We have seen that the time di?erence of the schemes in the
same group(RSAGroup or BilinearGroup) increases linearly with the number of
downloaded blocks m; in an application with a large number of the blocks a ﬁle
is divided into, the number of downloaded blocks can be very large. To transmit
a large ﬁle in a certain application, the dimension of the information part of the
blocks n has to be set to a relatively large value to let M meet the condition;
this will greatly lead to the increase of time di?erence since the operations that
depend on n will become costly. In a secure-critical system, we need to raise
the security parameter k to achieve a higher security level which will cause a
growth in the size of other parameters and then raise the processing time on the
intermediate nodes.
Second, the signature schemes in random oracle/standard models are some-
what comparable with small m and n and moderate k. The condition ’small
m and n’ is saying that the number of downloaded blocks on the intermediate
nodes and the dimension of the information vectors are small. As mentioned, to
limit the number of downloaded blocks, we can choose an application that set the
number of blocks a ﬁle is divided into to a small number. For the value of n,
when a small ﬁle is to be transmitted, we can play with n and set it to a small
value provided the condition of M(as deﬁned above) is met. Clearly, to achieve
a higher security level, more computations are required and this will lead to
worse performance. Therefore, for an application that is not secure-critical and is
used to transmit small ﬁles, the signature schemes in standard model(SRSA and
48SSDH) would be preferred; among SRSA and SSDH, SRSA is preferable since it
is time-saving to achieve the same security level as the SSDH.
Finally, a more customized implementation should be introduced to reduce
the processing overhead. From the above two aspects, there are circumstances in
which the schemes in random oracle/standard models are somewhat comparable.
To design a network coding application, we should carefully analyse the situation
where network coding signature schemes are applied and then decide whether to
use the schemes in random oracle or the schemes in standard model. To this end,
elements like the size andthe security level of the ﬁles should betaken into consid-
eration; and it is also worthwhile to consider the upper bound of each coordinates
intheblocks etc.. Forinstance, inanetwork coding applicationused tosend small
or large ﬁles, the number of blocks a ﬁle is divided into is ﬁxed to a small value;
either SRSAor SSDH canbeapplied since theirtimedi?erence doesn’t depend on
the value ofn and is insigniﬁcant with small m; if the application set M into large
value, then the processing time in each scheme will then be greatly reduced since
n will decrease. However, under these circumstances, two RSA-based schemes
are only comparable when the ﬁle is small since their time di?erence depends on
the valuesofmandn; if the ﬁleis larger, thetime di?erence will markedly extend.
Those are three perspectives concluded from what we have done to ﬁnd
out whether the standard schemes perform as well as the random oracle schemes.
Besides those, we also ﬁnd that the homomorphic signatures are far more expen-
sive than the vanilla network coding schemes. Though homomorphic signatures
can achieve a high security level to combat pollution attacks, e?ciency is to be
sacriﬁced since additional and expensive computations are done to achieve extra
security.
8.2 Critical Evaluations
The project is to compare the computational overhead of homomorphic network
coding signatures in random oracle and standard models to see whether the
random homomorphic signatures are comparable to the standard homomorphic
signatures. The purpose is fulﬁlled by implementing four secure network coding
signature schemes and comparing them group by group(RSAGroup and Bilinear-
Group). These choices are viewed as the schemes with a better performance than
other existing public-key homomorphic network coding signatures over the same
algebraic setting.
We illustrate three operations(vry NC(), vry Sig() and combine()) that will
lead to the cryptographic overhead on the intermediate nodes according to the
49communication model of homomorphic signatures in Section 5.2; and then we
show that the vry NC() will not result in the time di?erence by demonstrating
the implementation details of vry NC() in Section 6.1; these lead to the result
that our comparison concentrates on two operations, vry Sig() and combine().
Normally, in a network coding application, security parameter k, the upper
bound of each coordinate in the initial vectors M and the number of blocks a
ﬁle is divided into m are application-speciﬁc and they are ﬁxed once a certain
network coding application is chosen. Notice that when m and M are ﬁxed and
the generation size(the size of a ﬁle) is known, the value of n is determined. In
our implementation, each measurement is based on m blocks and, for simplicity,
we assume there is no download delay on the intermediate nodes; that is, we
assume that the number of downloaded blocks is equal to the number of blocks
a ﬁle is divided into. In RSAGroup and BilinearGroup, we measure how the
processing time of the veriﬁcation and combination algorithms changes with the
number of downloaded blocks m or the dimension of each block n respectively.
The experimental results are shown in bar charts or three-D line charts. These
ﬁgures give a vivid illustration of the variation tendency of the processing delay
when m or n increases and also how the time di?erence of cryptographic overhead
of the schemes in each group varies with m or n. The experimental results are
used to analyse the computational overhead in the signature schemes and can be
used to predict the changing tendency when m and n increase together or m or
n keeps growing to larger values. In addition, in RSAGroup, we examine how
the computational overhead changes when the security parameter k is doubled;
to achieve a higher security level, expensive computational overhead has to be
traded as well as the signiﬁcant communicational overhead.
We have shown the precise implementation details including how we choose
the parameters as deﬁned in the schemes in Chapter 6. The results are concluded
from the ﬁgures constructed from the experimental data, and in accordance with
each result, the analysis is discussed in detail from a theoretical point of view and
closely related to the deﬁnitions of the schemes.
Based on the implementation results of the four chosen schemes, we are
able to answer the question we pose at the very beginning of the project. Strictly
speaking, homomorphic signatures in standard model are not comparable to the
schemes in random oracle model when the network coding applications are used
to transmit large ﬁles and require a high security level; however, if only small
ﬁles are transferred and the ﬁles needn’t to be at a very high security level, the
signature schemes in random oracle/standard models are somewhat comparable.
50To conclude, the purpose of the project has been achieved by showing (1)
what operations will result in computational overhead, (2) how to measure and
compare each operation, (3) a detailed illustration of the experimental results
which are associated with theoretical analyses and (4) a precise conclusion.
The project is useful for further research on the performance of homomorphic
signatures in random oracle and standard models and can serve as guidelines for
choosing homomorphic signatures to apply to certain applications.
8.3 Possible Extensions
This section is going to discuss four possible extensions of the project. The
ﬁrst three possible extensions are aimed at improving the performance of the
signature schemes and reducing the time di?erence of the schemes in random
oracle/standard models; the last extension recommends a more practical way of
comparing the schemes in di?erent oracle models.
Optimized Pairing. To achieve a better performance of pairing opera-
tion, a good knowledge of pairing is required to select an elliptic curve to optimize
the operations that reach a certain security level. There is no doubt that this is a
complex task. In our project, PBC library is used to implement the pairing opera-
tion; as mentioned, the advantage of this library is that it allows the programmer
to do the implementation of pairing with little knowledge of cyclic groups and
the properties of pairing. Our choice of pairing is based on the descriptions of the
document of PBC library; as shown, type D pairing which is based on the curve
generated by applying complex multiplication method is the fastest type(o?ered
by the library) to generate asymmetric pairing. Though type D pairing is faster
than other types o?ered in the library, it has the drawback that the element size
?
inG is so large that it has resulted in the expensive exponentiation with the base
?
number chosen fromG. If an optimized elliptic curve can be chosen to reduce the
processing time of pairing operation as well as other operations with the bilinear
groups involved, the performance of two bilinear-based schemes will be improved
to a certain extent, and the time di?erence of their computational overhead will
become less signiﬁcant.
Optimized Implementation. For the optimization of implementation,
there are two aspects we will mention. First, it would be beneﬁcial to take
into account the implementation of certain operations. Our implementation just
follows thedeﬁnitions oftheschemes andtheequations intheschemes arerealized
step by step. Considerations like the optimization of multi-exponentiation are
not in the schedule of our project. As mentioned, the main operation that causes
51the time di?erence in two RSA-based schemes is one multi-exponentiation in the
combine algorithm; if the time for multi-exponentiation can be reduced, then
the condition that two RSA-based schemes are comparable is going to be more
ﬂexible. Besides, for the realization of the random oracle, we use the SHA2 hash
function in OpenSSL. Hash values are calculated on the intermediate nodes in
random oracle schemes; this will cause the processing overhead. It is wise to
think about choosing an e?cient and secure hash function or calling a more
e?cient SHA2 function in other libraries since the choice of hash function is the
key point to implement the random oracle schemes. The optimization of the
implementation should be aimed at achieving a better performance as well as
reaching the required security level.
Batch veriﬁcation. We have mentioned that three operations(vry NC(),
vry Sig() and combine()) will lead to the computational overhead on the interme-
diatenodes. Amongthosethreeoperations, theveriﬁcation ofsignaturesvry Sig()
is the most expensive one; so to reduce the processing overhead, we can focus on
the optimization of the vry Sig() algorithm by applying batch veriﬁcation. Batch
veriﬁcation[4] is an important technique to speed up block veriﬁcation. When
an intermediate node receives a number of blocks, say ?, instead of calling the
veriﬁcation function ? times on each block, it ﬁrst combines ? blocks into a new
coded one and then veriﬁes the new block; if the new block passes the veriﬁcation
check, this means that ? blocks pass the veriﬁcation check. Batch veriﬁcation has
greatly reduced the frequency of veriﬁcation from ? to 1; the veriﬁcation time has
1
improved 1? . To apply batch veriﬁcation, four signature schemes in our project
?
will speed up, especially two bilinear-based schemes which require two pairing
operations in one vry Sig(); furthermore, the time di?erence in two bilinear-based
schemes will be signiﬁcantly reduced(since their time di?erence is mainly caused
by vry Sig()).
Simulation. It is meaningful to compare the signature schemes in random
oracle/standard models by putting into practice the signature schemes using
simulation technique. The comparisonintheproject focusesonthecomputational
overhead of the schemes in di?erent oracle models on the intermediate nodes; the
download delay is assumed to be zero and the communicational overhead is not
taken into consideration either. To do the comparison in a more practical way, we
need to implement the schemes in certain network scenarios and compare them by
taking into account the communicational overhead andthe download delay. There
are many applications for building network simulators, such as OMNeT++[22]
and QualNet[24]; they o?er many network frameworks to support wireless ad-hoc
networks, sensor networks or photonic networks along with the network emulation
52and real-time simulation. Besides, the simulation will serve as a method to check
the feasibility of implementation by examining the throughput of the network
and the decoding probability(the probability to recover the original ﬁle) at the
targets.
The above four possible extensions are proposed based on the project and
they are meaningful points that future works can be focused on.
53References
[1] R. Ahlswede, Ning-Cai, S. Li, and R.W. Yeung. Network information ﬂow.
IEEE Transactions on Information Theory, 46(4):1204–1216, 2000.
[2] Nuttapong Attrapadung and Benoit Libert. Homomorphic network coding
signatures in the standard model. In Dario Catalano, Nelly Fazio, Rosario
Gennaro,andAntonioNicolosi, editors, PKC 2011: 14th International Work-
shop on Theory and Practice in Public Key Cryptography, volume 6571 of
Lecture Notes in Computer Sciene, pages 17–34, Taormina, Italy, March 6-9
2011. Springer, Berlin, Germany.
[3] Paulo S. L. M. Barreto and Michael Naehrig. Pairing-friendly elliptic curves
of primie order. In Selected Areas in Cryptography, pages 319–331, 2005.
[4] M. Bellare, J. Garay, and T. Rabin. Fast batch veriﬁcation for modu-
lar exponentiation and digital signatures. In Proc. Advances in Cryptol-
ogy(EUROCRYPT’98),LNCS, volume 1403, pages 236–250, 1998.
[5] Mihir Bellare and Phillip Rogaway. Random oracles are practical: A pradigm
fordesigning e?cientprotocols. InACM Conference on Computers and Com-
munication Security, pages 62–73, Nov. 1993.
[6] Dan Boneh and Xavier Boyen. Short signatures without random oracles and
the sdh assumption in bilinear groups. Journal of Cryptology, 21(2):149–177,
April 2008.
[7] Dan Boneh, David Freeman, Jonathan Katz, and Brent Waters. Signing a
linear subspace: Signature schemes for network coding. In Stanislaw Jarecki
and Gene Tsudik, editors, PKC 2009: 12th International Conference on The-
ory and Practice of Public Key Cryptography,volume5443ofLecture Notes in
Computer Science, pages 68–87, Irvine, CA, USA, March 18-20 2009. Spring,
Berlin, Germany.
[8] Dan Boneh and David Mandell Freeman. Homomorphic signatures for poly-
nomial functions. In Kenneth G. Paterson, editor, Advances in Cryptology
- EUROCRYPT 2011, volume 6632 of Lecture Notes in Computer Science,
Tallinn, Estonia, May 15-19 2011. Springer, Berlin, Germany.
[9] Dan Boneh and David Mandell Freeman. Linearly homomorphic signatures
over binary ﬁelds and new tools for lattice-based signatures. In Dario Cata-
lano,NellyFazio,RosarioGennaro, andAntonioNicolosi, editors, PKC 2011:
5414th International Workshop on Theory and Practice in Public Key Cryp-
tography, volume 6571 of Lecture Notes in Computer Science, pages 1–16,
Taormina, Italy, March 6–9 2011. Springer, Berlin, Germany.
[10] Ran Canetti, Oded Goldreich, and shai Halevi. The random oracle method-
ology, revisited. In 30th Annual ACM Symposium on Theory of Computing,
pages 209–218, Dallas, May 1998.
[11] DarioCatalano,DarioFiore,andBogdanWarinschi. E?cient networkcoding
signature in the standard model. In PKC 2012. Cryptology ePrint Archive
http://eprint.iacr.org/2011/696.
[12] Dario Catalano, Dario Fiore, and Bogdan Warinschi. Adaptive psedo-free
groups and applications. In Kenneth G. Paterson, editor, Advances in Cryp-
tology - EUPROCRYPT 2011, volume 6632 of Lecture Notes in Computer
Science, pages 207–223, Tallinn, Estonia, May 15-19 2011. Springer, Berlin,
Germany.
[13] Rosario Gennaro, Jonathan Katz, Hugo Krawczyk, and Tal Rabin. Secure
networkcodingovertheintegers. InPhongQ.NguyenandDavidPointcheval,
editors, PKC 2010: 13th International Conference on Theory and Practice of
Public Key Cryptography, volume 6065ofLecture Notes in Computer Science,
pages 142–160, Paris, France, May 26-28 2010. Springer, Berlin, Germany.
[14] T. Ho, R. Koetter, M. Medard, D. Karger, and M. E?ros. The beneﬁt of
codding over routing in a randomized setting. In Proc. of International Sym-
posium on Information Theory (ISIT), page 442, 2003.
[15] T. Ho, B. Leong, R. Koetter, M. Medard, M. e?ros, and D. Karger. Byzan-
tine modiﬁcation detection in multicast networks using randomized network
coding. In Proc. of International Symposium on Informatino Theory (ISIT),
pages 144–152, 2004.
[16] T. Ho, M. Medard, R. Koetter, D. Karger, M. E?ros, J. Shi, and B. Leong.
A random linear network coding approach to multicast. IEEE Transactions
on Information Theory, 52:4413–4430, 2006.
[17] Dennis Hofheinz and Eike Kiltz. Programmable hash functions and their
applications. In David Wagner, editor, Advances in Cryptology - CRYPTO
2008, volume 5157 of Lecture Notes in Computer Science, pages 21–38, Santa
Barbara, CA, USA, August 17–21 2008. Springer, Berlin, Germany.
55[18] S. Jaggi, M. Langberg, S. Katti, T. Ho, D. Katabi, M. Medard, and M. Ef-
fros. Resilient network coding in the presence of byzantine adversaries. IEEE
Transactions on Information Theory, 54:2596–2603, 2008.
[19] J. Katz and Y. Lindell. Introduction to modern cryptography. In Chapman
and Hall/CRC Cryptography, page 275, 2008.
[20] GMP Library. http://gmplib.org/.
[21] PBC Library. http://crypto.stanford.edu/pbc/.
[22] OMNeT++. http://www.omnetpp.org/.
[23] OpenSSL. http://www.openssl.org/.
[24] QualNet. http://www.scalable-networks.com/content/.
[25] Shuo-Yen Robert-Li, Raymond Y. Yeung, and Ning Cai. Linear network
coding. IEEE Transactions on Information Theory, 49(2):371–381, 2003.
[26] Brent Waters. Dual system encryption: Realizing fully secure ibe and hibe
under simple assumptions. In Shai Halevi, editor, Cryptology - CRYPTO
2009, volume 5677 of Lecture Notes in Computer Science, pages 619–636,
CA, USA, Auguest 16-20 2009. Springer, Berlin, Germany.
56